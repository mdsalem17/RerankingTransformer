{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import pickle_save, pickle_load\n",
    "from pprint import pprint\n",
    "from utils.data.delf import datum_io\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacred\n",
    "from sacred import SETTINGS\n",
    "from sacred.utils import apply_backspaces_and_linefeeds\n",
    "from numpy import linalg as LA\n",
    "from utils import pickle_load, pickle_save\n",
    "#from utils.revisited import compute_metrics\n",
    "from utils.data.delf import datum_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sacred.Experiment('Prepare Top-K (VIQUAE FOR RTT)', interactive=True)\n",
    "# Filter backspaces and linefeeds\n",
    "SETTINGS.CAPTURE_MODE = 'sys'\n",
    "ex.captured_out_filter = apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'r50_gldv1'\n",
    "set_name = 'dev'\n",
    "gnd_name = 'gnd_'+ set_name+'.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'viquae_for_rrt'\n",
    "data_dir = osp.join('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aqe = False\n",
    "aqe_params = {'k': 2, 'alpha': 0.3}\n",
    "\n",
    "save_nn_inds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir,  set_name+'_query.txt')) as fid:\n",
    "    query_lines   = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, set_name+'_gallery.txt')) as fid:\n",
    "    gallery_lines = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:12<00:00, 100.14it/s]\n"
     ]
    }
   ],
   "source": [
    "query_feats = []\n",
    "for i in tqdm(range(len(query_lines))):\n",
    "    name = osp.splitext(osp.basename(query_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, 'delg_' + feature_name, name + '.delg_global')\n",
    "    query_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_feats = np.stack(query_feats, axis=0)\n",
    "query_feats = query_feats / LA.norm(query_feats, axis=-1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Adding Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, set_name+'_selection.txt')) as fid:\n",
    "    selection_lines = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(selection_lines, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [14:50<00:00, 140.34it/s]\n"
     ]
    }
   ],
   "source": [
    "selection_feats = []\n",
    "for i in tqdm(range(len(selection_lines))):\n",
    "    name = osp.splitext(osp.basename(selection_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, 'delg_' + feature_name, name + '.delg_global')\n",
    "    selection_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1250,100,2048) (1250,1,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bee7c4755b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselection_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mselection_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection_feats\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1250,100,2048) (1250,1,100) "
     ]
    }
   ],
   "source": [
    "selection_feats = np.stack(selection_feats, axis=0)\n",
    "selection_feats = selection_feats / LA.norm(selection_feats, axis=-1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 100, 2048)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_feats = selection_feats.reshape(query_feats.shape[0], 100, query_feats.shape[1])\n",
    "selection_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for i in range(len(selection_feats)):\n",
    "    index_feats = np.stack(selection_feats[i], axis=0)\n",
    "    index_feats = index_feats / LA.norm(index_feats, axis=-1)[:, None]\n",
    "    sims.append(np.matmul(query_feats[i], index_feats.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.stack(sims, axis=0)\n",
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0785252 ,  0.00129219,  0.0785252 , ...,  0.25294203,\n",
       "         0.25294203,  0.25294203],\n",
       "       [ 0.14569354,  0.5770942 ,  0.09106596, ...,  0.6575873 ,\n",
       "         0.6575873 ,  0.6575873 ],\n",
       "       [ 0.35386312,  0.09078223,  0.13549596, ...,  0.17740631,\n",
       "         0.17740627,  0.17740627],\n",
       "       ...,\n",
       "       [ 0.55100095, -0.05612384,  0.5202445 , ...,  0.05114214,\n",
       "         0.5202446 ,  0.5510011 ],\n",
       "       [ 0.08045548,  0.4171785 ,  0.1148309 , ...,  0.3938345 ,\n",
       "         0.0804555 ,  0.5510011 ],\n",
       "       [ 0.06097266,  0.06173388,  0.42809194, ...,  0.25114518,\n",
       "         0.06173388,  0.5510011 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Adding Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_lines = np.genfromtxt('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/'+\n",
    "                                set_name+'_selection_imgs.txt', dtype='str')\n",
    "selection_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['512px-Lucas_Papademos.jpg', '512px-Zyp_Pfund1.jpg',\n",
       "       '512px-Zyp_Pfund1.jpg', '512px-Iakovidis_-_Kontostavlos.jpg',\n",
       "       '512px-Phoenix_Greek_coin_1828-1833.jpg',\n",
       "       '512px-Phoenix_Greek_coin_1828-1833.jpg',\n",
       "       '512px-Phoenix_Greek_coin_1828-1833.jpg',\n",
       "       '512px-1_obol,_Ionian_Islands,_1819.jpg', '512px-Drachmen.jpg',\n",
       "       '512px-Drachmen.jpg'], dtype='<U233')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_lines[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_img   = '.'.join((wiki_item['image'].split('.')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [13:35<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "selection_index_feats = []\n",
    "for i in tqdm(range(len(selection_lines))):\n",
    "    index_feats = []\n",
    "    for image_file in selection_lines[i]:\n",
    "        name = '.'.join((image_file.split('.')[:-1]))\n",
    "        path = osp.join(data_dir, 'delg_' + feature_name, name + '.delg_global')\n",
    "        index_feats.append(datum_io.ReadFromFile(path))\n",
    "    selection_index_feats.append(index_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(selection_index_feats[i]) for i in range(len(selection_index_feats))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 100, 2048)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_feats = np.stack(selection_index_feats, axis=0)\n",
    "selection_index_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selection_index_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1b36e7edf601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselection_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_index_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mindex_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_index_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#index_feats = index_feats / LA.norm(index_feats, axis=-1)[:, None]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mselection_sims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selection_index_feats' is not defined"
     ]
    }
   ],
   "source": [
    "selection_sims = []\n",
    "for i in range(len(selection_index_feats)):\n",
    "    index_feats = np.stack(selection_index_feats[i], axis=0)\n",
    "    #index_feats = index_feats / LA.norm(index_feats, axis=-1)[:, None]\n",
    "    selection_sims.append(np.matmul(query_feats[i], index_feats.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.array(selection_sims)\n",
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15160514, 0.25095916, 0.25095916, ..., 0.3012856 , 0.1246489 ,\n",
       "        0.26756623],\n",
       "       [0.08161078, 0.18024106, 0.09156677, ..., 0.72684175, 0.72684157,\n",
       "        0.72684157],\n",
       "       [0.07149097, 0.17137687, 0.11596002, ..., 0.25148824, 0.10830951,\n",
       "        0.22257602],\n",
       "       ...,\n",
       "       [0.27738544, 0.60081625, 0.12173056, ..., 0.4982748 , 0.38213605,\n",
       "        0.33787534],\n",
       "       [0.11040592, 0.49454427, 0.08045548, ..., 0.1148309 , 0.5187907 ,\n",
       "        0.32204676],\n",
       "       [0.60081625, 0.60081625, 0.15237401, ..., 0.35443673, 0.11360757,\n",
       "        0.55823565]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_aqe:\n",
    "    alpha = aqe_params['alpha']\n",
    "    nn_inds = np.argsort(-sims, -1)\n",
    "    query_aug = deepcopy(query_feats)\n",
    "    for i in range(len(query_feats)):\n",
    "        new_q = [query_feats[i]]\n",
    "        for j in range(aqe_params['k']):\n",
    "            nn_id = nn_inds[i, j]\n",
    "            weight = sims[i, nn_id] ** aqe_params['alpha']\n",
    "            new_q.append(weight * index_feats[nn_id])\n",
    "        new_q = np.stack(new_q, 0)\n",
    "        new_q = np.mean(new_q, axis=0)\n",
    "        query_aug[i] = new_q/LA.norm(new_q, axis=-1)\n",
    "    sims = np.matmul(query_aug, index_feats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2048)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_inds = np.argsort(-sims, -1)\n",
    "nn_dists = deepcopy(sims)\n",
    "for i in range(query_feats.shape[0]):\n",
    "    index_feats = selection_index_feats[i]\n",
    "    for j in range(index_feats.shape[0]):\n",
    "        nn_dists[i, j] = sims[i, nn_inds[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_nn_inds:\n",
    "    output_path = osp.join(data_dir, set_name + '_nn_inds_%s.pkl' % feature_name)\n",
    "    pickle_save(output_path, nn_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(ranks, nres):\n",
    "    \"\"\"\n",
    "    Computes average precision for given ranked indexes.\n",
    "    \n",
    "    It assumes that `ranks` contains the ranks for all expected positive\n",
    "    index images to be retrieved. If `positive_ranks` is empty, returns\n",
    "    `average_precision` = 0.\n",
    "    Note that average precision computation here does NOT use the finite sum\n",
    "    method (see\n",
    "    https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision)\n",
    "    which is common in information retrieval literature. Instead, the method\n",
    "    implemented here integrates over the precision-recall curve by averaging two\n",
    "    adjacent precision points, then multiplying by the recall step. This is the\n",
    "    convention for the Revisited Oxford/Paris datasets.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    ranks : zerro-based ranks of positive images\n",
    "    nres  : number of positive images\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ap    : average precision\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # number of images ranked by the system\n",
    "    nimgranks = len(ranks)\n",
    "\n",
    "    # accumulate trapezoids in PR-plot\n",
    "    ap = 0\n",
    "\n",
    "    recall_step = 1. / nres\n",
    "\n",
    "    for j in np.arange(nimgranks):\n",
    "        rank = ranks[j]\n",
    "\n",
    "        if rank == 0:\n",
    "            precision_0 = 1.\n",
    "        else:\n",
    "            precision_0 = float(j) / rank\n",
    "\n",
    "        precision_1 = float(j + 1) / (rank + 1)\n",
    "\n",
    "        ap += (precision_0 + precision_1) * recall_step / 2.\n",
    "\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map(ranks, gnd, kappas=[]):\n",
    "    \"\"\"\n",
    "    Computes the mAP for a given set of returned results.\n",
    "\n",
    "         Usage: \n",
    "           map = compute_map (ranks, gnd) \n",
    "                 computes mean average precsion (map) only\n",
    "        \n",
    "           map, aps, pr, prs = compute_map (ranks, gnd, kappas) \n",
    "                 computes mean average precision (map), average precision (aps) for each query\n",
    "                 computes mean precision at kappas (pr), precision at kappas (prs) for each query\n",
    "        \n",
    "         Notes:\n",
    "         1) ranks starts from 0, ranks.shape = db_size X #queries\n",
    "         2) The junk results (e.g., the query itself) should be declared in the gnd stuct array\n",
    "         3) If there are no positive images for some query, that query is excluded from the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    map = 0.\n",
    "    nq = len(gnd) # number of queries\n",
    "    aps = np.zeros(nq)\n",
    "    pr = np.zeros(len(kappas))\n",
    "    prs = np.zeros((nq, len(kappas)))\n",
    "    nempty = 0\n",
    "\n",
    "    for i in np.arange(nq):\n",
    "        qgnd = np.array(gnd[i]['ok'])\n",
    "        qgndj = np.array(gnd[i]['junk'])\n",
    "\n",
    "        # no positive groundtruth images, skip from the average\n",
    "        if qgnd.shape[0] == 0:\n",
    "            aps[i] = 0\n",
    "            prs[i, :] = 0\n",
    "            continue\n",
    "\n",
    "        # only negative images retrieved in the IR step\n",
    "        if qgnd.shape[0] > 100:\n",
    "            aps[i] = 0.\n",
    "            prs[i, :] = 0.\n",
    "            continue\n",
    "        \n",
    "        # sorted positions of positive and junk images (0 based)\n",
    "        pos  = np.arange(ranks.shape[0])[np.isin(ranks[:,i], qgnd)]\n",
    "        junk = np.arange(ranks.shape[0])[np.isin(ranks[:,i], qgndj)]\n",
    "\n",
    "        k = 0\n",
    "        ij = 0\n",
    "        if len(junk):\n",
    "            # decrease positions of positives based on the number of\n",
    "            # junk images appearing before them\n",
    "            ip = 0\n",
    "            while (ip < len(pos)):\n",
    "                while (ij < len(junk) and pos[ip] > junk[ij]):\n",
    "                    k += 1\n",
    "                    ij += 1\n",
    "                pos[ip] = pos[ip] - k\n",
    "                ip += 1\n",
    "\n",
    "        # compute ap\n",
    "        ap = compute_ap(pos, len(qgnd))\n",
    "        map = map + ap\n",
    "        aps[i] = ap\n",
    "\n",
    "        # compute precision @ k\n",
    "        pos += 1 # get it to 1-based\n",
    "        for j in np.arange(len(kappas)):\n",
    "            if len(pos) == 0:\n",
    "                max_pos = kappas[j]\n",
    "            else: max_pos = max(pos)\n",
    "            kq = min(max_pos, kappas[j]); \n",
    "            prs[i, j] = (pos <= kq).sum() / kq\n",
    "        pr = pr + prs[i, :]\n",
    "\n",
    "    map = map / nq # (nq - nempty)\n",
    "    pr = pr /nq # (nq - nempty)\n",
    "\n",
    "    return map, aps, pr, prs, nempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, gnd_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([89, 90, 97, 96, 99, 98, 95, 92, 94, 93, 91,  3, 22, 21, 20, 19, 17,\n",
       "        18, 16, 64, 30, 26, 31, 29, 28, 25, 27, 50, 46, 45, 87, 86, 80, 84,\n",
       "        83, 85, 81, 78, 82, 79,  8,  7,  6,  5, 76, 77, 75, 73, 74, 41, 40,\n",
       "        39, 38, 88, 52, 53, 54, 55, 56, 51, 15, 11, 47,  1, 23, 24, 12, 37,\n",
       "        36, 33, 34, 35, 32, 44, 49, 48, 42, 43,  2, 70, 69, 68, 67, 66, 65,\n",
       "        61, 63, 62, 60,  4,  0, 57, 13, 14,  9, 71, 72, 59, 58, 10]),\n",
       " [100, 101, 102, 103, 104])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.T[:,1], gnd_data['gnd'][1]['hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([86]),)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(nn_inds.T[:,0]==10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 63, 76, 77, 78, 79, 80, 82, 85, 86, 87, 88, 89, 90, 91, 93, 98,\n",
       "        99]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69,\n",
       "        70, 71, 72, 73, 74, 75, 81, 83, 84, 92, 94, 95, 96, 97]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos  = np.arange(nn_inds.T.shape[0])[np.isin(nn_inds.T[:,0], gnd_data['gnd'][0]['hard'])]\n",
    "junk = np.arange(nn_inds.T.shape[0])[np.isin(nn_inds.T[:,0], gnd_data['gnd'][0]['junk'])]\n",
    "pos, junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset, ranks, gnd, kappas=[1, 5, 10]):\n",
    "    print(ranks.shape)\n",
    "    \n",
    "    # old evaluation protocol\n",
    "    if dataset.startswith('classic'):\n",
    "        map, aps, _, _ = compute_map(ranks, gnd)\n",
    "        out = {'map': np.around(map*100, decimals=3)}\n",
    "        print('>> {}: mAP {:.2f}'.format(dataset, out['map']))\n",
    "\n",
    "    # new evaluation protocol\n",
    "    elif dataset.startswith('viquae'):\n",
    "        \n",
    "        gnd_t = []\n",
    "        for i in range(len(gnd)):\n",
    "            g = {}\n",
    "            g['ok'] = np.concatenate([gnd[i]['hard']])\n",
    "            g['junk'] = np.concatenate([gnd[i]['junk']])\n",
    "            gnd_t.append(g)\n",
    "        mapH, apsH, mprH, prsH, nempty = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "\n",
    "        out = {\n",
    "            'H_map': np.around(mapH*100, decimals=2),\n",
    "            'H_mp':  np.around(mprH*100, decimals=2),\n",
    "        }\n",
    "\n",
    "        print('>> {}: mAP H: {}'.format(dataset, out['H_map']))\n",
    "        print('>> {}: mP@k{} H: {}'.format(dataset, kappas, out['H_mp']))\n",
    "\n",
    "    return out, mapH, apsH, mprH, prsH, nempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gnd_data['gnd'][10]['junk']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), [100, 101, 102])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(nn_inds.T.shape[0])[np.in1d(nn_inds.T[:,i], gnd_data['gnd'][10]['hard'])], gnd_data['gnd'][10]['hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1250)\n",
      ">> viquae: mAP H: 40.0\n",
      ">> viquae: mP@k[1, 5, 6, 10, 100] H: [40. 40. 40. 40. 40.]\n"
     ]
    }
   ],
   "source": [
    "out, mapH, apsH, mprH, prsH, nempty = compute_metrics('viquae', nn_inds.T, gnd_data['gnd'][:5], kappas=[1,5,6,10,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prsH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/anaconda3/envs/rrt/lib/python3.7/site-packages/ranx/qrels_run_common.py:7: UserWarning: Sorting disabled. Assumes that you provided sorted doc_ids!\n",
      "  warnings.warn(\"Sorting disabled. Assumes that you provided sorted doc_ids!\")\n"
     ]
    }
   ],
   "source": [
    "from ranx import Qrels, Run, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "run_dict = {}\n",
    "for i in range(nn_inds.shape[0]):\n",
    "    q_str = 'q_' + str(i)\n",
    "    \n",
    "    qrels_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in gnd_data['gnd'][i]['hard']])\n",
    "    run_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in nn_inds.T[:,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run\n",
    "\n",
    "qrels = Qrels(qrels_dict)\n",
    "run = Run(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': 0.12856755624751715,\n",
       " 'map@1': 0.014668052638023897,\n",
       " 'map@5': 0.031033820826130022,\n",
       " 'map@10': 0.042207224808062216,\n",
       " 'mrr': 0.1812249528163731,\n",
       " 'mrr@1': 0.112,\n",
       " 'mrr@5': 0.1550133333333333,\n",
       " 'mrr@10': 0.16596063492063493,\n",
       " 'precision': 0.0884,\n",
       " 'precision@1': 0.112,\n",
       " 'precision@5': 0.088,\n",
       " 'precision@10': 0.0816}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ranx import evaluate\n",
    "\n",
    "evaluate(qrels, run, [\"map\", \"map@1\", \"map@5\", \"map@10\",\n",
    "                      \"mrr\", \"mrr@1\", \"mrr@5\", \"mrr@10\",\n",
    "                      \"precision\", \"precision@1\", \"precision@5\", \"precision@10\"])\n",
    "# ValueError: Metric  not supported. Supported metrics are `hits`, `hit_rate`,\n",
    "# `precision`, `recall`, `f1`, `r-precision`, `mrr`, `map`, `ndcg`, and `ndcg_burges`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset, ranks, gnd, kappas=[1, 5, 10]):\n",
    "   \n",
    "    from ranx import Qrels, Run, evaluate\n",
    "    qrels_dict = {}\n",
    "    run_dict = {}\n",
    "    for i in range(ranks.T.shape[0]):\n",
    "        q_str = 'q_' + str(i)\n",
    "\n",
    "        qrels_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in gnd[i]['hard']])\n",
    "        run_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in ranks[:,i]])    \n",
    "    \n",
    "    qrels = Qrels(qrels_dict)\n",
    "    run = Run(run_dict)\n",
    "\n",
    "    out = evaluate(qrels, run, [\"map\", \"map@\"+str(kappas[0]), \"map@\"+str(kappas[1]), \"map@\"+str(kappas[2]),\n",
    "                      \"mrr\", \"mrr@\"+str(kappas[0]), \"mrr@\"+str(kappas[1]), \"mrr@\"+str(kappas[2]),\n",
    "                      \"precision\", \"precision@\"+str(kappas[0]), \"precision@\"+str(kappas[1]), \"precision@\"+str(kappas[2])])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': 0.12856755624751715,\n",
       " 'map@1': 0.014668052638023897,\n",
       " 'map@5': 0.031033820826130022,\n",
       " 'map@10': 0.042207224808062216,\n",
       " 'mrr': 0.1812249528163731,\n",
       " 'mrr@1': 0.112,\n",
       " 'mrr@5': 0.1550133333333333,\n",
       " 'mrr@10': 0.16596063492063493,\n",
       " 'precision': 0.0884,\n",
       " 'precision@1': 0.112,\n",
       " 'precision@5': 0.088,\n",
       " 'precision@10': 0.0816}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics('viquae', nn_inds.T, gnd_data['gnd'], kappas=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
