{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import pickle_save, pickle_load\n",
    "from pprint import pprint\n",
    "from utils.data.delf import datum_io\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacred\n",
    "from sacred import SETTINGS\n",
    "from sacred.utils import apply_backspaces_and_linefeeds\n",
    "from numpy import linalg as LA\n",
    "from utils import pickle_load, pickle_save\n",
    "from utils.revisited import compute_metrics\n",
    "from utils.data.delf import datum_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function compute_metrics in module utils.revisited:\n",
      "\n",
      "compute_metrics(dataset, ranks, gnd, sizes=[], kappas=[1, 5, 10], set_name=None, max_sequence_len=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sacred.Experiment('Prepare Top-K (VIQUAE FOR RTT)', interactive=True)\n",
    "# Filter backspaces and linefeeds\n",
    "SETTINGS.CAPTURE_MODE = 'sys'\n",
    "ex.captured_out_filter = apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'imagenet_r50'\n",
    "set_name = 'tuto'\n",
    "gnd_name = 'gnd_'+ set_name+'.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'viquae_for_rrt'\n",
    "data_dir = osp.join('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False\n",
    "use_aqe = False\n",
    "aqe_params = {'k': 2, 'alpha': 0.3}\n",
    "\n",
    "save_nn_inds = True\n",
    "prefixed = 'humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file     = prefixed + '_'+ set_name+'_query.txt'\n",
    "gallery_file   = prefixed + '_'+ set_name+'_gallery.txt'\n",
    "selection_file = prefixed + '_'+ set_name+'_selection.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, query_file)) as fid:\n",
    "    query_lines   = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 682.43it/s]\n"
     ]
    }
   ],
   "source": [
    "query_feats = []\n",
    "for i in tqdm(range(len(query_lines))):\n",
    "    name = osp.splitext(osp.basename(query_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, feature_name, name + '.imagenet')\n",
    "    query_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_feats = np.stack(query_feats, axis=0)\n",
    "query_feats = query_feats / LA.norm(query_feats, axis=-1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, selection_file)) as fid:\n",
    "    selection_lines = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3089,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(selection_lines, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'512px-Ruby_Dee_speaking.jpg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osp.basename(selection_lines[i].split(';;')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3089 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/imagenet_r50/512px-Jack_Ruby-1.delg_global; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a4b5d8dd51c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.delg_global'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mindex_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RerankingTransformer/RRT_GLD/utils/data/delf/datum_io.py\u001b[0m in \u001b[0;36mReadFromFile\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \"\"\"\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rrt/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rrt/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     78\u001b[0m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0;32m---> 79\u001b[0;31m           self.__name, 1024 * 512)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/imagenet_r50/512px-Jack_Ruby-1.delg_global; No such file or directory"
     ]
    }
   ],
   "source": [
    "index_feats = []\n",
    "for i in tqdm(range(len(selection_lines))):\n",
    "    name = osp.splitext(osp.basename(selection_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, feature_name, name+'.delg_global')\n",
    "    print(type(datum_io.ReadFromFile(path)))\n",
    "    index_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 2048)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_feats = np.zeros((query_feats.shape[0], 100, query_feats.shape[1]))\n",
    "selection_index_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, gnd_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4838"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_sizes = [len(gnd_data['simlist'][i]) for i in range(len(gnd_data['simlist']))]\n",
    "np.sum(selection_index_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0\n",
    "counter = 0\n",
    "for i in range(selection_index_feats.shape[0]):\n",
    "    for j in range(selection_index_feats.shape[1]):\n",
    "        if j < selection_index_sizes[i]:\n",
    "            selection_index_feats[i][j] = index_feats[counter]\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/anaconda3/envs/rrt/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(selection_index_feats.shape[0]):\n",
    "    selection_index_feats[i] = selection_index_feats[i]/LA.norm(selection_index_feats[i], axis=-1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for i in range(len(selection_index_feats)):\n",
    "    index_feats = np.stack(selection_index_feats[i], axis=0)\n",
    "    sims.append(np.matmul(query_feats[i], index_feats.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.stack(sims, axis=0)\n",
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04103276,  0.16977126,  0.18141674, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.33237307,  0.3944457 ,  0.42619404, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.33237307,  0.30754114,  0.44644287, ...,         nan,\n",
       "                nan,         nan],\n",
       "       ...,\n",
       "       [ 0.19000561, -0.01076683,  0.03394178, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.04822452,  0.24529736,  0.21718944, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.03589981,  0.16352484,  0.21618424, ...,         nan,\n",
       "                nan,         nan]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5162, 4838)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(sims)), np.count_nonzero(~np.isnan(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_aqe:\n",
    "    alpha = aqe_params['alpha']\n",
    "    nn_inds = np.argsort(-sims, -1)\n",
    "    query_aug = deepcopy(query_feats)\n",
    "    for i in range(len(query_feats)):\n",
    "        new_q = [query_feats[i]]\n",
    "        for j in range(aqe_params['k']):\n",
    "            nn_id = nn_inds[i, j]\n",
    "            weight = sims[i, nn_id] ** aqe_params['alpha']\n",
    "            new_q.append(weight * index_feats[nn_id])\n",
    "        new_q = np.stack(new_q, 0)\n",
    "        new_q = np.mean(new_q, axis=0)\n",
    "        query_aug[i] = new_q/LA.norm(new_q, axis=-1)\n",
    "    sims = np.matmul(query_aug, index_feats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2048)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_index_feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_inds = np.argsort(-sims, -1)\n",
    "nn_dists = deepcopy(sims)\n",
    "for i in range(query_feats.shape[0]):\n",
    "    index_feats = selection_index_feats[i]\n",
    "    for j in range(index_feats.shape[0]):\n",
    "        nn_dists[i, j] = sims[i, nn_inds[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53691091, 0.48823032, 0.3786902 , ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.50516481, 0.46841804, 0.44644287, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.50516481, 0.46841804, 0.45547155, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [0.24880777, 0.19662176, 0.19087987, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.27114646, 0.24529736, 0.21771399, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.26374199, 0.24880777, 0.22943023, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(selection_index_sizes)):\n",
    "    size = selection_index_sizes[i]\n",
    "    if max(nn_inds[i][:size]) > size:\n",
    "        print('Ewwwwwwwwwwwww')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_nn_inds:\n",
    "    if use_aqe:\n",
    "        output_file = set_name +'_aqe_nn_inds_%s.pkl' % feature_name\n",
    "    else:\n",
    "        output_file = set_name + '_nn_inds_%s.pkl' % feature_name\n",
    "\n",
    "    if training:\n",
    "        output_file = 'training_'+ output_file\n",
    "\n",
    "    output_path = osp.join(data_dir, output_file)\n",
    "    pickle_save(output_path, nn_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.revisited import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 30.28, 'mrr': 41.97, 'precision': 13.64, 'hit_rate': 83.0, 'recall': 82.5, 'map@1': 10.25, 'mrr@1': 29.0, 'precision@1': 29.0, 'hit_rate@1': 29.0, 'recall@1': 10.25, 'map@5': 17.72, 'mrr@5': 39.85, 'precision@5': 18.8, 'hit_rate@5': 56.0, 'recall@5': 26.02, 'map@10': 21.21, 'mrr@10': 40.93, 'precision@10': 16.6, 'hit_rate@10': 63.0, 'recall@10': 35.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map': 30.28,\n",
       " 'mrr': 41.97,\n",
       " 'precision': 13.64,\n",
       " 'hit_rate': 83.0,\n",
       " 'recall': 82.5,\n",
       " 'map@1': 10.25,\n",
       " 'mrr@1': 29.0,\n",
       " 'precision@1': 29.0,\n",
       " 'hit_rate@1': 29.0,\n",
       " 'recall@1': 10.25,\n",
       " 'map@5': 17.72,\n",
       " 'mrr@5': 39.85,\n",
       " 'precision@5': 18.8,\n",
       " 'hit_rate@5': 56.0,\n",
       " 'recall@5': 26.02,\n",
       " 'map@10': 21.21,\n",
       " 'mrr@10': 40.93,\n",
       " 'precision@10': 16.6,\n",
       " 'hit_rate@10': 63.0,\n",
       " 'recall@10': 35.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, gnd_name))\n",
    "compute_metrics('viquae', nn_inds.T, gnd_data['gnd'], selection_index_sizes, kappas=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.revisited import compute_ap, compute_map\n",
    "from ranx import Qrels, Run, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd[i]['provenance_entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset, ranks, gnd, sizes=[], kappas=[1, 5, 10]):\n",
    "    # old evaluation protocol\n",
    "    if dataset.startswith('classic'):\n",
    "        map, aps, _, _ = compute_map(ranks, gnd)\n",
    "        out = {'map': np.around(map*100, decimals=3)}\n",
    "        print('>> {}: mAP {:.2f}'.format(dataset, out['map']))\n",
    "\n",
    "    # new evaluation protocol for viquae dataset\n",
    "    elif dataset.startswith('viquae'):\n",
    "        metrics = [\"map\", \"mrr\", \"precision\", \"hit_rate\", \"recall\"]\n",
    "        m_list = [metric for metric in metrics]\n",
    "\n",
    "        for i in range(len(kappas)):\n",
    "            m_list.extend([metric+'@'+str(kappas[i]) for metric in metrics])\n",
    "        \n",
    "        qrels_dict = {}\n",
    "        run_dict = {}\n",
    "        \n",
    "        for i in range(ranks.T.shape[0]):\n",
    "            size = sizes[i]\n",
    "            q_str = \"q_\"+str(int(i))\n",
    "            if gnd[i]['provenance_entity']:\n",
    "                ok_inds = gnd[i]['r_hard']\n",
    "            else:\n",
    "                ok_inds = np.concatenate([gnd[i]['r_easy'], gnd[i]['r_hard']])\n",
    "            \n",
    "            if len(ok_inds) == 0:\n",
    "                qrels_dict[q_str] = {\"DUMMY_RUN\": 0}\n",
    "            else:\n",
    "                qrels_dict[q_str] = dict([('d_' + str(int(key)), 1) for key in ok_inds])\n",
    "            \n",
    "            run_dict[q_str]   = dict([('d_' + str(int(key)), 1) for key in ranks[:size,i]])\n",
    "\n",
    "        qrels = Qrels(qrels_dict)\n",
    "        run = Run(run_dict)\n",
    "        out = evaluate(qrels, run, m_list)\n",
    "        for key, value in out.items():\n",
    "            out[key] = np.around(value*100, decimals=2)\n",
    "    print(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 30.28, 'mrr': 41.97, 'precision': 13.64, 'hit_rate': 83.0, 'recall': 82.5, 'map@1': 10.25, 'mrr@1': 29.0, 'precision@1': 29.0, 'hit_rate@1': 29.0, 'recall@1': 10.25, 'map@5': 17.72, 'mrr@5': 39.85, 'precision@5': 18.8, 'hit_rate@5': 56.0, 'recall@5': 26.02, 'map@10': 21.21, 'mrr@10': 40.93, 'precision@10': 16.6, 'hit_rate@10': 63.0, 'recall@10': 35.0}\n"
     ]
    }
   ],
   "source": [
    "kappas=[1,5,10]\n",
    "ranks, gnd, sizes = nn_inds.T, gnd_data['gnd'], selection_index_sizes\n",
    "\n",
    "metrics = [\"map\", \"mrr\", \"precision\", \"hit_rate\", \"recall\"]\n",
    "m_list = [metric for metric in metrics]\n",
    "\n",
    "for i in range(len(kappas)):\n",
    "    m_list.extend([metric+'@'+str(kappas[i]) for metric in metrics])\n",
    "\n",
    "qrels_dict = {}\n",
    "run_dict = {}\n",
    "\n",
    "for i in range(ranks.T.shape[0]):\n",
    "    size = sizes[i]\n",
    "    q_str = \"q_\"+str(int(i))\n",
    "    ok_inds = np.concatenate([gnd[i]['r_easy'], gnd[i]['r_hard']])\n",
    "    \n",
    "    if len(ok_inds) == 0:\n",
    "        qrels_dict[q_str] = {\"DUMMY_RUN\": 0}\n",
    "    else:\n",
    "        qrels_dict[q_str] = dict([('d_' + str(int(key)), 1) for key in ok_inds])\n",
    "    run_dict[q_str]   = dict([('d_' + str(int(key)), 1) for key in ranks[:size,i]])\n",
    "\n",
    "qrels = Qrels(qrels_dict)\n",
    "run = Run(run_dict)\n",
    "out = evaluate(qrels, run, m_list)\n",
    "for key, value in out.items():\n",
    "    out[key] = np.around(value*100, decimals=2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dict\n",
    "[k for k,v in run_dict.items() if v == {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 30.28, 'mrr': 41.97, 'precision': 13.64, 'hit_rate': 83.0, 'recall': 82.5, 'map@1': 10.25, 'mrr@1': 29.0, 'precision@1': 29.0, 'hit_rate@1': 29.0, 'recall@1': 10.25, 'map@5': 17.72, 'mrr@5': 39.85, 'precision@5': 18.8, 'hit_rate@5': 56.0, 'recall@5': 26.02, 'map@10': 21.21, 'mrr@10': 40.93, 'precision@10': 16.6, 'hit_rate@10': 63.0, 'recall@10': 35.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map': 30.28,\n",
       " 'mrr': 41.97,\n",
       " 'precision': 13.64,\n",
       " 'hit_rate': 83.0,\n",
       " 'recall': 82.5,\n",
       " 'map@1': 10.25,\n",
       " 'mrr@1': 29.0,\n",
       " 'precision@1': 29.0,\n",
       " 'hit_rate@1': 29.0,\n",
       " 'recall@1': 10.25,\n",
       " 'map@5': 17.72,\n",
       " 'mrr@5': 39.85,\n",
       " 'precision@5': 18.8,\n",
       " 'hit_rate@5': 56.0,\n",
       " 'recall@5': 26.02,\n",
       " 'map@10': 21.21,\n",
       " 'mrr@10': 40.93,\n",
       " 'precision@10': 16.6,\n",
       " 'hit_rate@10': 63.0,\n",
       " 'recall@10': 35.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, gnd_name))\n",
    "compute_metrics('viquae', nn_inds.T, gnd_data['gnd'], selection_index_sizes, kappas=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
