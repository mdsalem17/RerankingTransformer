{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle, json, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import os.path as osp\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacred\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sacred import SETTINGS\n",
    "from sacred.utils import apply_backspaces_and_linefeeds\n",
    "from torch.backends import cudnn\n",
    "from torch.optim import SGD, Adam, AdamW, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.backends import cudnn\n",
    "# from visdom_logger import VisdomLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, BatchSampler\n",
    "from typing import NamedTuple, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.matcher import MatchERT, PosMatchERT\n",
    "from models.ingredient import model_ingredient, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ingredient import model_ingredient, get_model\n",
    "from utils import state_dict_to_cpu, num_of_trainable_params\n",
    "from utils import pickle_load, pickle_save\n",
    "#from utils.data.utils import TripletSampler\n",
    "from utils import BinaryCrossEntropyWithLogits\n",
    "from utils.data.dataset_ingredient import data_ingredient, get_loaders\n",
    "from utils.training import train_one_epoch, evaluate_viquae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pickle_load\n",
    "from sacred import Experiment\n",
    "from utils.data.dataset_ingredient import data_ingredient, get_loaders\n",
    "from utils.data.dataset import FeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sacred.Experiment('RRT Training', ingredients=[data_ingredient, model_ingredient], interactive=True)\n",
    "# Filter backspaces and linefeeds\n",
    "SETTINGS.CAPTURE_MODE = 'sys'\n",
    "ex.captured_out_filter = apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.0001\n",
    "momentum = 0.\n",
    "nesterov = False\n",
    "weight_decay = 5e-4\n",
    "optim = 'adamw'\n",
    "scheduler = 'multistep'\n",
    "max_norm = 0.0\n",
    "seed = 0\n",
    "\n",
    "visdom_port = None\n",
    "visdom_freq = 100\n",
    "cpu = False  # Force training on CPU\n",
    "cudnn_flag = 'benchmark'\n",
    "temp_dir = osp.join('outputs', 'temp')\n",
    "\n",
    "no_bias_decay = False\n",
    "loss = 'bce'\n",
    "scheduler_tau = [16, 18]\n",
    "scheduler_gamma = 0.1\n",
    "\n",
    "resume = '/mnt/beegfs/home/smessoud/RerankingTransformer/RRT_GLD/rrt_gld_ckpts/r50_gldv2.pt'\n",
    "freeze = True\n",
    "#resume = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " False,\n",
       " 'benchmark',\n",
       " None,\n",
       " 100,\n",
       " 'outputs/temp',\n",
       " 0,\n",
       " False,\n",
       " 0.0,\n",
       " '/mnt/beegfs/home/smessoud/RerankingTransformer/RRT_GLD/rrt_gld_ckpts/r50_gldv2.pt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, cpu, cudnn_flag, visdom_port, visdom_freq, temp_dir, seed, no_bias_decay, max_norm, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_scheduler(parameters, optim, loader_length, epochs, lr, momentum, nesterov, weight_decay, scheduler, scheduler_tau, scheduler_gamma, lr_step=None):\n",
    "    if optim == 'sgd':\n",
    "        optimizer = SGD(parameters, lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True if nesterov and momentum else False)\n",
    "    elif optim == 'adam':\n",
    "        optimizer = Adam(parameters, lr=lr, weight_decay=weight_decay) \n",
    "    else:\n",
    "        optimizer = AdamW(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    if epochs == 0:\n",
    "        scheduler = None\n",
    "        update_per_iteration = None\n",
    "    elif scheduler == 'cos':\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs * loader_length, eta_min=0.000005)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.000001)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'warmcos':\n",
    "        # warm_cosine = lambda i: min((i + 1) / 3, (1 + math.cos(math.pi * i / (epochs * loader_length))) / 2)\n",
    "        warm_cosine = lambda i: min((i + 1) / 3, (1 + math.cos(math.pi * i / epochs)) / 2)\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=warm_cosine)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'multistep':\n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=scheduler_tau, gamma=scheduler_gamma)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'warmstep':\n",
    "        warm_step = lambda i: min((i + 1) / 100, 1) * 0.1 ** (i // (lr_step * loader_length))\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=warm_step)\n",
    "        update_per_iteration = True\n",
    "    else:\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, epochs * loader_length)\n",
    "        update_per_iteration = True\n",
    "\n",
    "    return optimizer, (scheduler, update_per_iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss):\n",
    "    if loss == 'bce':\n",
    "        return BinaryCrossEntropyWithLogits()\n",
    "    else:\n",
    "        raise Exception('Unsupported loss {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() and not cpu else 'cpu')\n",
    "# callback = VisdomLogger(port=visdom_port) if visdom_port else None\n",
    "if cudnn_flag == 'deterministic':\n",
    "    setattr(cudnn, cudnn_flag, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tuto_viquae_tuto_r50_gldv2'\n",
    "set_name = 'tuto'\n",
    "train_txt = ('tuto_query.txt', 'tuto_gallery.txt')\n",
    "test_txt = ('tuto_query.txt', 'tuto_selection.txt')\n",
    "train_data_dir = 'data/viquae_for_rrt'\n",
    "test_data_dir  = 'data/viquae_for_rrt'\n",
    "test_gnd_file = 'gnd_tuto.pkl'\n",
    "train_gnd_file = 'gnd_'+set_name+'.pkl'\n",
    "desc_name = 'r50_gldv2'\n",
    "sampler = 'triplet'\n",
    "split_char  = ';;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'train_viquae_dev_r50_gldv2'\n",
    "set_name = 'train'\n",
    "train_txt = (set_name+'_query.txt', set_name+'_gallery.txt')\n",
    "test_txt = ('dev_query.txt', 'dev_selection.txt')\n",
    "train_data_dir = 'data/viquae_for_rrt'\n",
    "test_data_dir  = 'data/viquae_for_rrt'\n",
    "train_gnd_file = 'gnd_train.pkl'\n",
    "test_gnd_file = 'gnd_dev.pkl'\n",
    "desc_name = 'r50_gldv2'\n",
    "sampler = 'triplet'\n",
    "split_char  = ';;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(desc_name, \n",
    "        train_data_dir, test_data_dir, \n",
    "        train_txt, test_txt, train_gnd_file,\n",
    "        test_gnd_file, max_sequence_len,\n",
    "        split_char):\n",
    "    ####################################################################################################################################\n",
    "    train_gnd_data  = None if train_gnd_file is None else pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "    train_lines     = read_file(osp.join(train_data_dir, train_txt[1]))\n",
    "    train_q_lines   = read_file(osp.join(train_data_dir, train_txt[0]))\n",
    "    train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "    train_q_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_q_lines]\n",
    "    train_set       = FeatureDataset(train_data_dir, train_samples,   desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "    query_train_set = FeatureDataset(train_data_dir, train_q_samples, desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "    ####################################################################################################################################\n",
    "    test_gnd_data = None if test_gnd_file is None else pickle_load(osp.join(test_data_dir, test_gnd_file))\n",
    "    query_lines   = read_file(osp.join(test_data_dir, test_txt[0]))\n",
    "    gallery_lines = read_file(osp.join(test_data_dir, test_txt[1]))\n",
    "    query_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in query_lines]\n",
    "    gallery_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in gallery_lines]\n",
    "    gallery_set = FeatureDataset(test_data_dir, gallery_samples, desc_name, max_sequence_len)\n",
    "    query_set   = FeatureDataset(test_data_dir, query_samples,   desc_name, max_sequence_len, gnd_data=test_gnd_data)\n",
    "        \n",
    "    return (train_set, query_train_set), (query_set, gallery_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(desc_name, train_data_dir, \n",
    "    batch_size, test_batch_size, \n",
    "    num_workers, pin_memory, \n",
    "    sampler, recalls, set_name,\n",
    "    num_candidates=300,):\n",
    "\n",
    "    (train_set, query_train_set), (query_set, gallery_set) = get_sets(\n",
    "        desc_name=desc_name, train_data_dir=train_data_dir, \n",
    "        test_data_dir=train_data_dir, train_txt=train_txt, \n",
    "        test_txt=test_txt, train_gnd_file=train_gnd_file, \n",
    "        test_gnd_file=test_gnd_file, \n",
    "        max_sequence_len=max_sequence_len, \n",
    "        split_char=split_char)\n",
    "\n",
    "    if sampler == 'random':\n",
    "        train_sampler = BatchSampler(RandomSampler(train_set), batch_size=batch_size, drop_last=False)\n",
    "    elif sampler == 'triplet':\n",
    "        #s_name = set_name\n",
    "        #if s_name != '':\n",
    "        #    s_name = set_name + '_'\n",
    "        #def map_nnids_labels(train_data_dir, train_gnd_file, s_categories):\n",
    "        #    gnd =  pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "        #    selection_gallery = gnd['simlist']\n",
    "        #    s_categories = s_categories.reshape(np.array(selection_gallery).shape)\n",
    "        #    selection_ids_to_cat_dict = [{k: s_categories[i][k] for k in range(len(selection_gallery[i]))} for i in range(len(selection_gallery))]\n",
    "        #    return selection_ids_to_cat_dict\n",
    "        #s_path = train_data_dir+'/'+set_name+'_s_categories.txt'\n",
    "        #print('s_path: ', s_path)\n",
    "        #s_categories = np.loadtxt(s_path, dtype='int64')\n",
    "        #print('s_categories: ', s_categories.shape)\n",
    "        #map_nnids_labels = map_nnids_labels(train_data_dir, train_gnd_file, s_categories)\n",
    "        train_nn_inds = osp.join(train_data_dir, set_name + '_nn_inds_%s.pkl'%desc_name)\n",
    "        gnd_data = train_set.gnd_data['gnd']\n",
    "        train_sampler = TripletSampler(query_train_set.targets, batch_size, train_nn_inds, num_candidates, gnd_data)\n",
    "    else:\n",
    "        raise ValueError('Invalid choice of sampler ({}).'.format(sampler))\n",
    "    train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    query_train_loader = DataLoader(query_train_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "    query_loader   = DataLoader(query_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    gallery_loader = DataLoader(gallery_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return MetricLoaders(train=train_loader, query_train=query_train_loader, query=query_loader, gallery=gallery_loader, num_classes=len(train_set.categories),set_name=set_name), recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLoaders(NamedTuple):\n",
    "    train: DataLoader\n",
    "    num_classes: int\n",
    "    query: DataLoader\n",
    "    query_train: DataLoader\n",
    "    set_name: str = ''\n",
    "    gallery: Optional[DataLoader] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size      = 36\n",
    "test_batch_size = 36\n",
    "max_sequence_len = 500\n",
    "num_workers = 8  # number of workers used ot load the data\n",
    "pin_memory  = True  # use the pin_memory option of DataLoader \n",
    "num_candidates = 100\n",
    "recalls = [1, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSampler():\n",
    "    def __init__(self, labels, batch_size, nn_inds_path, num_candidates, gnd_data, min_pos=1):\n",
    "        self.batch_size     = batch_size\n",
    "        self.num_candidates = num_candidates\n",
    "        self.cache_nn_inds  = pickle_load(nn_inds_path)\n",
    "        self.labels = labels\n",
    "        self.gnd_data = gnd_data\n",
    "        print('nn_inds_path: ', nn_inds_path)\n",
    "        print('labels len: ', len(labels))\n",
    "        assert (len(self.cache_nn_inds) == len(labels))\n",
    "        #############################################################################\n",
    "        ## Collect valid tuples\n",
    "        valids = np.zeros_like(labels)\n",
    "        for i in range(len(self.cache_nn_inds)):\n",
    "            positives = self.gnd_data[i]['r_easy']\n",
    "            negatives = self.gnd_data[i]['r_junk']\n",
    "            if len(positives) < min_pos or len(negatives) < min_pos:\n",
    "                continue\n",
    "            valids[i] = 1\n",
    "        self.valids = np.where(valids > 0)[0]\n",
    "        self.num_samples = len(self.valids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        cands = torch.randperm(self.num_samples).tolist()\n",
    "        for i in range(len(cands)):\n",
    "            query_idx = self.valids[cands[i]]\n",
    "            anchor_idx = self.gnd_data[query_idx]['anchor_idx']\n",
    "            \n",
    "            positive_inds = self.gnd_data[query_idx]['g_easy']\n",
    "            negative_inds = self.gnd_data[query_idx]['g_junk']\n",
    "            assert(len(positive_inds) > 0)\n",
    "            assert(len(negative_inds) > 0)\n",
    "\n",
    "            random.shuffle(positive_inds)\n",
    "            random.shuffle(negative_inds)\n",
    "\n",
    "            batch.append(anchor_idx)\n",
    "            batch.append(positive_inds[0]) \n",
    "            batch.append(negative_inds[0])\n",
    "\n",
    "            if len(batch) >= self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                \n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_samples * 3 + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds_path = '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/'+set_name+'_nn_inds_r50_gldv1.pkl'\n",
    "cache_nn_inds  = pickle_load(nn_inds_path)\n",
    "cache_nn_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_inds_path:  /mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/train_nn_inds_r50_gldv2.pkl\n",
      "labels len:  1190\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "loaders, recall_ks = get_loaders('r50_gldv2', train_data_dir, \n",
    "    batch_size, test_batch_size, \n",
    "    num_workers, pin_memory, \n",
    "    sampler, recalls, set_name,\n",
    "    num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_global_features, num_local_features, seq_len, dim_K, dim_feedforward, nhead, num_encoder_layers, dropout, activation, normalize_before, use_pos):\n",
    "    \n",
    "    if use_pos:\n",
    "        return PosMatchERT(d_global=num_global_features, d_model=num_local_features, seq_len=seq_len, d_K=dim_K, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, activation=activation, normalize_before=normalize_before)\n",
    "    \n",
    "    else:\n",
    "        return MatchERT(d_global=num_global_features, d_model=num_local_features, seq_len=seq_len, d_K=dim_K, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, activation=activation, normalize_before=normalize_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'rrt'\n",
    "num_global_features = 2048  \n",
    "num_local_features = 128  \n",
    "seq_len = 1004\n",
    "dim_K = 256\n",
    "dim_feedforward = 1024\n",
    "nhead = 4\n",
    "num_encoder_layers = 6\n",
    "dropout = 0.2\n",
    "activation = \"relu\"\n",
    "normalize_before = False\n",
    "use_pos = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nname = \\'vrrt\\'\\nseq_len = 1004\\ndim_K = 256\\ndim_feedforward = 1024\\nnhead = 8\\nnum_encoder_layers = 8\\ndropout = 0.4 \\nactivation = \"relu\"\\nnormalize_before = False\\nuse_pos = True\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "name = 'vrrt'\n",
    "seq_len = 1004\n",
    "dim_K = 256\n",
    "dim_feedforward = 1024\n",
    "nhead = 8\n",
    "num_encoder_layers = 8\n",
    "dropout = 0.4 \n",
    "activation = \"relu\"\n",
    "normalize_before = False\n",
    "use_pos = True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+1)\n",
    "model = get_model(num_global_features,num_local_features,seq_len,dim_K,dim_feedforward,nhead,num_encoder_layers,dropout,activation,normalize_before,use_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchERT(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (remap): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (scale_encoder): Embedding(7, 128)\n",
       "  (seg_encoder): Embedding(6, 128)\n",
       "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if freeze:\n",
    "    #freeze all layers of the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #unfreeze the classfication layers\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    #for param in model.seg_encoder.parameters():\n",
    "    #    param.requires_grad = True\n",
    "    #for param in model.scale_encoder.parameters():\n",
    "    #    param.requires_grad = True\n",
    "    #for param in model.remap.parameters():\n",
    "    #    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameters:  129\n"
     ]
    }
   ],
   "source": [
    "if resume is not None:\n",
    "    checkpoint = torch.load(resume, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['state'], strict=True)\n",
    "print('# of trainable parameters: ', num_of_trainable_params(model))\n",
    "class_loss = get_loss(loss)\n",
    "nn_inds_path = osp.join(loaders.query.dataset.data_dir, loaders.set_name + '_nn_inds_%s.pkl'%loaders.query.dataset.desc_name)\n",
    "cache_nn_inds = torch.from_numpy(pickle_load(nn_inds_path)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 264065, 2243201)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(129, 264065, 2243201) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+2)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "parameters = []\n",
    "if no_bias_decay:\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() != 1]})\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() == 1], 'weight_decay': 0})\n",
    "else:\n",
    "    parameters.append({'params': model.parameters()})\n",
    "optimizer, scheduler = get_optimizer_scheduler(parameters=parameters, loader_length=len(loaders.train),\n",
    "                                               optim=optim, epochs=epochs, lr=lr,\n",
    "                                               momentum=momentum, nesterov=nesterov, weight_decay=weight_decay,\n",
    "                                               scheduler=scheduler, scheduler_tau=scheduler_tau, \n",
    "                                               scheduler_gamma=scheduler_gamma, lr_step=None)\n",
    "if resume is not None and checkpoint.get('optim', None) is not None:\n",
    "    optimizer.load_state_dict(checkpoint['optim'])\n",
    "    del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import *\n",
    "def evaluate_viquae(\n",
    "        model: nn.Module,\n",
    "        cache_nn_inds: torch.Tensor,\n",
    "        query_loader: DataLoader,\n",
    "        gallery_loader: DataLoader,\n",
    "        recall: List[int]):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    to_device = lambda x: x.to(device, non_blocking=True)\n",
    "\n",
    "    query_global, query_local, query_mask, query_scales, query_positions, query_names = [], [], [], [], [], []\n",
    "    gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names = [], [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for entry in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "            q_global, q_local, q_mask, q_scales, q_positions, _, q_names = entry\n",
    "            query_global.append(q_global.cpu())\n",
    "            query_local.append(q_local.cpu())\n",
    "            query_mask.append(q_mask.cpu())\n",
    "            query_scales.append(q_scales.cpu())\n",
    "            query_positions.append(q_positions.cpu())\n",
    "            query_names.extend(list(q_names))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        query_global    = torch.cat(query_global, 0)\n",
    "        query_local     = torch.cat(query_local, 0)\n",
    "        query_mask      = torch.cat(query_mask, 0)\n",
    "        query_scales    = torch.cat(query_scales, 0)\n",
    "        query_positions = torch.cat(query_positions, 0)\n",
    "\n",
    "        for entry in tqdm(gallery_loader, desc='Extracting gallery features', leave=False, ncols=80):\n",
    "            g_global, g_local, g_mask, g_scales, g_positions, _, g_names = entry\n",
    "            gallery_global.append(g_global.cpu())\n",
    "            gallery_local.append(g_local.cpu())\n",
    "            gallery_mask.append(g_mask.cpu())\n",
    "            gallery_scales.append(g_scales.cpu())\n",
    "            gallery_positions.append(g_positions.cpu())\n",
    "            gallery_names.extend(list(g_names))\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        gallery_global    = torch.cat(gallery_global, 0)\n",
    "        gallery_local     = torch.cat(gallery_local, 0)\n",
    "        gallery_mask      = torch.cat(gallery_mask, 0)\n",
    "        gallery_scales    = torch.cat(gallery_scales, 0)\n",
    "        gallery_positions = torch.cat(gallery_positions, 0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        evaluate_function = partial(mean_average_precision_viquae_rerank, model=model, cache_nn_inds=cache_nn_inds,\n",
    "            query_global=query_global, query_local=query_local, query_mask=query_mask, query_scales=query_scales, query_positions=query_positions, \n",
    "            gallery_global=gallery_global, gallery_local=gallery_local, gallery_mask=gallery_mask, gallery_scales=gallery_scales, gallery_positions=gallery_positions, \n",
    "            ks=recall, \n",
    "            gnd=query_loader.dataset.gnd_data,\n",
    "        )\n",
    "        metrics = evaluate_function()\n",
    "    return metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_entry_once(\n",
    "    query_loader: DataLoader,\n",
    "    gallery_loader: DataLoader):\n",
    "    \n",
    "    query_global, query_local, query_mask, query_scales, query_positions, query_names = [], [], [], [], [], []\n",
    "    gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names = [], [], [], [], [], []\n",
    "\n",
    "    print(\"READING ENTRIES FOR THE FIRST TIME\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for entry in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "            q_global, q_local, q_mask, q_scales, q_positions, _, q_names = entry\n",
    "            query_global.append(q_global.cpu())\n",
    "            query_local.append(q_local.cpu())\n",
    "            query_mask.append(q_mask.cpu())\n",
    "            query_scales.append(q_scales.cpu())\n",
    "            query_positions.append(q_positions.cpu())\n",
    "            query_names.extend(list(q_names))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        query_global    = torch.cat(query_global, 0)\n",
    "        query_local     = torch.cat(query_local, 0)\n",
    "        query_mask      = torch.cat(query_mask, 0)\n",
    "        query_scales    = torch.cat(query_scales, 0)\n",
    "        query_positions = torch.cat(query_positions, 0)\n",
    "\n",
    "        for entry in tqdm(gallery_loader, desc='Extracting gallery features', leave=False, ncols=80):\n",
    "            g_global, g_local, g_mask, g_scales, g_positions, _, g_names = entry\n",
    "            gallery_global.append(g_global.cpu())\n",
    "            gallery_local.append(g_local.cpu())\n",
    "            gallery_mask.append(g_mask.cpu())\n",
    "            gallery_scales.append(g_scales.cpu())\n",
    "            gallery_positions.append(g_positions.cpu())\n",
    "            gallery_names.extend(list(g_names))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        gallery_global    = torch.cat(gallery_global, 0)\n",
    "        gallery_local     = torch.cat(gallery_local, 0)\n",
    "        gallery_mask      = torch.cat(gallery_mask, 0)\n",
    "        gallery_scales    = torch.cat(gallery_scales, 0)\n",
    "        gallery_positions = torch.cat(gallery_positions, 0)\n",
    "    \n",
    "    query_feats   = [query_global, query_local, query_mask, query_scales, query_positions, query_names]\n",
    "    gallery_feats = [gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names]\n",
    "    \n",
    "    return query_feats, gallery_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import mean_average_precision_viquae_rerank\n",
    "\n",
    "def fast_evaluate_viquae(\n",
    "    model: nn.Module,\n",
    "    cache_nn_inds: torch.Tensor,\n",
    "    query_loader: DataLoader,\n",
    "    gallery_loader: DataLoader,\n",
    "    recall: List[int],\n",
    "    query_feats, \n",
    "    gallery_feats):\n",
    "    \n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    to_device = lambda x: x.to(device, non_blocking=True)\n",
    "    \n",
    "    if len(query_feats) == 0:\n",
    "        query_feats, gallery_feats = read_entry_once(query_loader, gallery_loader)\n",
    "    \n",
    "    query_global, query_local, query_mask, query_scales, query_positions, query_names = query_feats\n",
    "    gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names = gallery_feats\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    fast_evaluate_function = partial(mean_average_precision_viquae_rerank, model=model, cache_nn_inds=cache_nn_inds,\n",
    "        query_global=query_global, query_local=query_local, query_mask=query_mask, query_scales=query_scales, query_positions=query_positions, \n",
    "        gallery_global=gallery_global, gallery_local=gallery_local, gallery_mask=gallery_mask, gallery_scales=gallery_scales, gallery_positions=gallery_positions, \n",
    "        ks=recall, \n",
    "        gnd=query_loader.dataset.gnd_data,\n",
    "    )\n",
    "    metrics = fast_evaluate_function()\n",
    "    \n",
    "    return metrics, query_feats, gallery_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_feats, gallery_feats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+3)\n",
    "# setup partial function to simplify call\n",
    "\n",
    "eval_function = partial(fast_evaluate_viquae, model=model, \n",
    "    cache_nn_inds=cache_nn_inds,\n",
    "    recall=recall_ks, query_loader=loaders.query, gallery_loader=loaders.gallery,\n",
    "    query_feats=query_feats, gallery_feats=gallery_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Extracting query features:   0%|                         | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING ENTRIES FOR THE FIRST TIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting gallery features:  21%|██▎        | 364/1738 [05:00<21:28,  1.07it/s]"
     ]
    }
   ],
   "source": [
    "result, query_feats, gallery_feats = eval_function()\n",
    "pprint(result)\n",
    "best_val = (0, result, deepcopy(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_name = osp.join(temp_dir, '{}_{}.pt'.format(ex.current_run.config['model']['name'],\n",
    "#                                                         ex.current_run.config['dataset']['name']))\n",
    "\n",
    "save_name = 'temp_outputs/tf_models/rrt_train_viquae_dev_r50_gldv2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training   [000]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameters:  1979136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [000]: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.22it/s]\n",
      "100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Training   [001]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 31.45, 'mrr': 44.18, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 11.75, 'mrr@1': 34.17, 'precision@1': 34.17, 'hit_rate@1': 34.17, 'recall@1': 11.75, 'map@5': 17.72, 'mrr@5': 41.35, 'precision@5': 19.33, 'hit_rate@5': 51.67, 'recall@5': 20.65, 'map@10': 21.44, 'mrr@10': 43.25, 'precision@10': 17.17, 'hit_rate@10': 65.0, 'recall@10': 32.6}\n",
      "Validation [000]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 34.17,\n",
      " 'hit_rate@10': 65.0,\n",
      " 'hit_rate@5': 51.67,\n",
      " 'map': 31.45,\n",
      " 'map@1': 11.75,\n",
      " 'map@10': 21.44,\n",
      " 'map@5': 17.72,\n",
      " 'mrr': 44.18,\n",
      " 'mrr@1': 34.17,\n",
      " 'mrr@10': 43.25,\n",
      " 'mrr@5': 41.35,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 34.17,\n",
      " 'precision@10': 17.17,\n",
      " 'precision@5': 19.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 11.75,\n",
      " 'recall@10': 32.6,\n",
      " 'recall@5': 20.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [001]: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 31.18, 'mrr': 43.08, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 11.28, 'mrr@1': 31.67, 'precision@1': 31.67, 'hit_rate@1': 31.67, 'recall@1': 11.28, 'map@5': 17.55, 'mrr@5': 40.31, 'precision@5': 19.83, 'hit_rate@5': 51.67, 'recall@5': 20.87, 'map@10': 21.26, 'mrr@10': 42.22, 'precision@10': 17.67, 'hit_rate@10': 65.83, 'recall@10': 32.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training   [002]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [001]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 31.67,\n",
      " 'hit_rate@10': 65.83,\n",
      " 'hit_rate@5': 51.67,\n",
      " 'map': 31.18,\n",
      " 'map@1': 11.28,\n",
      " 'map@10': 21.26,\n",
      " 'map@5': 17.55,\n",
      " 'mrr': 43.08,\n",
      " 'mrr@1': 31.67,\n",
      " 'mrr@10': 42.22,\n",
      " 'mrr@5': 40.31,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 31.67,\n",
      " 'precision@10': 17.67,\n",
      " 'precision@5': 19.83,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 11.28,\n",
      " 'recall@10': 32.54,\n",
      " 'recall@5': 20.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [002]: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|██████████| 100/100 [01:14<00:00,  1.35it/s]\n",
      "Training   [003]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 31.17, 'mrr': 43.52, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 11.38, 'mrr@1': 33.33, 'precision@1': 33.33, 'hit_rate@1': 33.33, 'recall@1': 11.38, 'map@5': 17.56, 'mrr@5': 40.72, 'precision@5': 20.17, 'hit_rate@5': 51.67, 'recall@5': 21.06, 'map@10': 21.25, 'mrr@10': 42.57, 'precision@10': 17.67, 'hit_rate@10': 65.0, 'recall@10': 32.13}\n",
      "Validation [002]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 33.33,\n",
      " 'hit_rate@10': 65.0,\n",
      " 'hit_rate@5': 51.67,\n",
      " 'map': 31.17,\n",
      " 'map@1': 11.38,\n",
      " 'map@10': 21.25,\n",
      " 'map@5': 17.56,\n",
      " 'mrr': 43.52,\n",
      " 'mrr@1': 33.33,\n",
      " 'mrr@10': 42.57,\n",
      " 'mrr@5': 40.72,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 33.33,\n",
      " 'precision@10': 17.67,\n",
      " 'precision@5': 20.17,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 11.38,\n",
      " 'recall@10': 32.13,\n",
      " 'recall@5': 21.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [003]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "100%|██████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 31.11, 'mrr': 42.86, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 10.94, 'mrr@1': 31.67, 'precision@1': 31.67, 'hit_rate@1': 31.67, 'recall@1': 10.94, 'map@5': 17.66, 'mrr@5': 40.24, 'precision@5': 20.67, 'hit_rate@5': 52.5, 'recall@5': 21.76, 'map@10': 21.23, 'mrr@10': 41.93, 'precision@10': 17.67, 'hit_rate@10': 65.0, 'recall@10': 32.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training   [004]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [003]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 31.67,\n",
      " 'hit_rate@10': 65.0,\n",
      " 'hit_rate@5': 52.5,\n",
      " 'map': 31.11,\n",
      " 'map@1': 10.94,\n",
      " 'map@10': 21.23,\n",
      " 'map@5': 17.66,\n",
      " 'mrr': 42.86,\n",
      " 'mrr@1': 31.67,\n",
      " 'mrr@10': 41.93,\n",
      " 'mrr@5': 40.24,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 31.67,\n",
      " 'precision@10': 17.67,\n",
      " 'precision@5': 20.67,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 10.94,\n",
      " 'recall@10': 32.32,\n",
      " 'recall@5': 21.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [004]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      " 20%|██        | 20/100 [00:14<01:00,  1.33it/s]"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed+1)\n",
    "model = get_model(num_global_features,\n",
    "                  num_local_features,\n",
    "                  seq_len,dim_K,\n",
    "                  dim_feedforward,\n",
    "                  nhead,\n",
    "                  num_encoder_layers,\n",
    "                  dropout,\n",
    "                  activation,\n",
    "                  normalize_before,\n",
    "                  use_pos)\n",
    "\n",
    "#freeze all layers of the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#unfreeze the classfication layers\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.seg_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.scale_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.remap.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if resume is not None:\n",
    "    checkpoint = torch.load(resume, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['state'], strict=True)\n",
    "print('# of trainable parameters: ', num_of_trainable_params(model))\n",
    "class_loss = get_loss(loss)\n",
    "nn_inds_path = osp.join(loaders.query.dataset.data_dir, loaders.set_name + '_nn_inds_%s.pkl'%loaders.query.dataset.desc_name)\n",
    "cache_nn_inds = torch.from_numpy(pickle_load(nn_inds_path)).long()\n",
    "\n",
    "torch.manual_seed(seed+2)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "parameters = []\n",
    "if no_bias_decay:\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() != 1]})\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() == 1], 'weight_decay': 0})\n",
    "else:\n",
    "    parameters.append({'params': model.parameters()})\n",
    "optimizer, scheduler = get_optimizer_scheduler(parameters=parameters, loader_length=len(loaders.train),\n",
    "                                               optim=optim, epochs=epochs, lr=lr,\n",
    "                                               momentum=momentum, nesterov=nesterov, weight_decay=weight_decay,\n",
    "                                               scheduler=scheduler, scheduler_tau=scheduler_tau, \n",
    "                                               scheduler_gamma=scheduler_gamma, lr_step=None)\n",
    "if resume is not None and checkpoint.get('optim', None) is not None:\n",
    "    optimizer.load_state_dict(checkpoint['optim'])\n",
    "    del checkpoint\n",
    "\n",
    "for epoch in range(5):\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    train_one_epoch(model=model, loader=loaders.train, class_loss=class_loss, optimizer=optimizer, scheduler=scheduler, max_norm=max_norm, epoch=epoch, freq=visdom_freq, ex=None)\n",
    "    \n",
    "    # validation\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, False)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    result, query_feats, gallery_feats = fast_evaluate_viquae(model=model,\n",
    "                                                              cache_nn_inds=cache_nn_inds,\n",
    "                                                              recall=recall_ks,\n",
    "                                                              query_loader=loaders.query, \n",
    "                                                              gallery_loader=loaders.gallery,\n",
    "                                                              query_feats=query_feats, \n",
    "                                                              gallery_feats=gallery_feats)\n",
    "    \n",
    "    print('Validation [{:03d}]'.format(epoch)), pprint(result)\n",
    "    #ex.log_scalar('val.map', result['map'], step=epoch + 1)\n",
    "\n",
    "    if result['map'] >= best_val[1]['map']:\n",
    "        print('New best model in epoch %d.'%epoch)\n",
    "        best_val = (epoch + 1, result, deepcopy(model.state_dict()))\n",
    "        #torch.save({'state': state_dict_to_cpu(best_val[2]), 'optim': optimizer.state_dict()}, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [000]: 100%|█████████████████████████| 10/10 [00:20<00:00,  2.04s/it]\n",
      "100%|██████████| 100/100 [03:33<00:00,  2.13s/it]\n",
      "Training   [001]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.89, 'mrr': 33.76, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 8.22, 'mrr@1': 21.67, 'precision@1': 21.67, 'hit_rate@1': 21.67, 'recall@1': 8.22, 'map@5': 13.95, 'mrr@5': 30.92, 'precision@5': 15.33, 'hit_rate@5': 45.83, 'recall@5': 20.55, 'map@10': 16.92, 'mrr@10': 32.32, 'precision@10': 13.83, 'hit_rate@10': 55.83, 'recall@10': 28.24}\n",
      "Validation [000]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 21.67,\n",
      " 'hit_rate@10': 55.83,\n",
      " 'hit_rate@5': 45.83,\n",
      " 'map': 26.89,\n",
      " 'map@1': 8.22,\n",
      " 'map@10': 16.92,\n",
      " 'map@5': 13.95,\n",
      " 'mrr': 33.76,\n",
      " 'mrr@1': 21.67,\n",
      " 'mrr@10': 32.32,\n",
      " 'mrr@5': 30.92,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 21.67,\n",
      " 'precision@10': 13.83,\n",
      " 'precision@5': 15.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 8.22,\n",
      " 'recall@10': 28.24,\n",
      " 'recall@5': 20.55}\n",
      "New best model in epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [001]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]\n",
      "Training   [002]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.93, 'mrr': 33.4, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 8.17, 'mrr@1': 20.83, 'precision@1': 20.83, 'hit_rate@1': 20.83, 'recall@1': 8.17, 'map@5': 14.0, 'mrr@5': 30.57, 'precision@5': 15.33, 'hit_rate@5': 45.83, 'recall@5': 20.55, 'map@10': 17.01, 'mrr@10': 31.89, 'precision@10': 13.83, 'hit_rate@10': 55.0, 'recall@10': 28.13}\n",
      "Validation [001]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 20.83,\n",
      " 'hit_rate@10': 55.0,\n",
      " 'hit_rate@5': 45.83,\n",
      " 'map': 26.93,\n",
      " 'map@1': 8.17,\n",
      " 'map@10': 17.01,\n",
      " 'map@5': 14.0,\n",
      " 'mrr': 33.4,\n",
      " 'mrr@1': 20.83,\n",
      " 'mrr@10': 31.89,\n",
      " 'mrr@5': 30.57,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 20.83,\n",
      " 'precision@10': 13.83,\n",
      " 'precision@5': 15.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 8.17,\n",
      " 'recall@10': 28.13,\n",
      " 'recall@5': 20.55}\n",
      "New best model in epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [002]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n",
      "Training   [003]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.96, 'mrr': 33.82, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 8.22, 'mrr@1': 21.67, 'precision@1': 21.67, 'hit_rate@1': 21.67, 'recall@1': 8.22, 'map@5': 14.02, 'mrr@5': 30.99, 'precision@5': 15.33, 'hit_rate@5': 45.83, 'recall@5': 20.55, 'map@10': 17.04, 'mrr@10': 32.3, 'precision@10': 13.83, 'hit_rate@10': 55.0, 'recall@10': 28.13}\n",
      "Validation [002]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 21.67,\n",
      " 'hit_rate@10': 55.0,\n",
      " 'hit_rate@5': 45.83,\n",
      " 'map': 26.96,\n",
      " 'map@1': 8.22,\n",
      " 'map@10': 17.04,\n",
      " 'map@5': 14.02,\n",
      " 'mrr': 33.82,\n",
      " 'mrr@1': 21.67,\n",
      " 'mrr@10': 32.3,\n",
      " 'mrr@5': 30.99,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 21.67,\n",
      " 'precision@10': 13.83,\n",
      " 'precision@5': 15.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 8.22,\n",
      " 'recall@10': 28.13,\n",
      " 'recall@5': 20.55}\n",
      "New best model in epoch 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [003]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n",
      "Training   [004]:   0%|                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.96, 'mrr': 33.82, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 8.22, 'mrr@1': 21.67, 'precision@1': 21.67, 'hit_rate@1': 21.67, 'recall@1': 8.22, 'map@5': 14.02, 'mrr@5': 30.99, 'precision@5': 15.33, 'hit_rate@5': 45.83, 'recall@5': 20.55, 'map@10': 17.04, 'mrr@10': 32.3, 'precision@10': 13.83, 'hit_rate@10': 55.0, 'recall@10': 28.13}\n",
      "Validation [003]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 21.67,\n",
      " 'hit_rate@10': 55.0,\n",
      " 'hit_rate@5': 45.83,\n",
      " 'map': 26.96,\n",
      " 'map@1': 8.22,\n",
      " 'map@10': 17.04,\n",
      " 'map@5': 14.02,\n",
      " 'mrr': 33.82,\n",
      " 'mrr@1': 21.67,\n",
      " 'mrr@10': 32.3,\n",
      " 'mrr@5': 30.99,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 21.67,\n",
      " 'precision@10': 13.83,\n",
      " 'precision@5': 15.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 8.22,\n",
      " 'recall@10': 28.13,\n",
      " 'recall@5': 20.55}\n",
      "New best model in epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   [004]: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "100%|██████████| 100/100 [02:54<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.96, 'mrr': 33.82, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 8.22, 'mrr@1': 21.67, 'precision@1': 21.67, 'hit_rate@1': 21.67, 'recall@1': 8.22, 'map@5': 14.02, 'mrr@5': 30.99, 'precision@5': 15.33, 'hit_rate@5': 45.83, 'recall@5': 20.55, 'map@10': 17.04, 'mrr@10': 32.3, 'precision@10': 13.83, 'hit_rate@10': 55.0, 'recall@10': 28.13}\n",
      "Validation [004]\n",
      "{'hit_rate': 85.0,\n",
      " 'hit_rate@1': 21.67,\n",
      " 'hit_rate@10': 55.0,\n",
      " 'hit_rate@5': 45.83,\n",
      " 'map': 26.96,\n",
      " 'map@1': 8.22,\n",
      " 'map@10': 17.04,\n",
      " 'map@5': 14.02,\n",
      " 'mrr': 33.82,\n",
      " 'mrr@1': 21.67,\n",
      " 'mrr@10': 32.3,\n",
      " 'mrr@5': 30.99,\n",
      " 'precision': 13.83,\n",
      " 'precision@1': 21.67,\n",
      " 'precision@10': 13.83,\n",
      " 'precision@5': 15.33,\n",
      " 'recall': 84.58,\n",
      " 'recall@1': 8.22,\n",
      " 'recall@10': 28.13,\n",
      " 'recall@5': 20.55}\n",
      "New best model in epoch 4.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    train_one_epoch(model=model, loader=loaders.train, class_loss=class_loss, optimizer=optimizer, scheduler=scheduler, max_norm=max_norm, epoch=epoch, freq=visdom_freq, ex=None)\n",
    "    \n",
    "    # validation\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, False)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    result, query_feats, gallery_feats = fast_evaluate_viquae(model=model,\n",
    "                                                              cache_nn_inds=cache_nn_inds,\n",
    "                                                              recall=recall_ks,\n",
    "                                                              query_loader=loaders.query, \n",
    "                                                              gallery_loader=loaders.gallery,\n",
    "                                                              query_feats=query_feats, \n",
    "                                                              gallery_feats=gallery_feats)\n",
    "    \n",
    "    print('Validation [{:03d}]'.format(epoch)), pprint(result)\n",
    "    #ex.log_scalar('val.map', result['map'], step=epoch + 1)\n",
    "\n",
    "    if result['map'] >= best_val[1]['map']:\n",
    "        print('New best model in epoch %d.'%epoch)\n",
    "        best_val = (epoch + 1, result, deepcopy(model.state_dict()))\n",
    "        #torch.save({'state': state_dict_to_cpu(best_val[2]), 'optim': optimizer.state_dict()}, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training import *\n",
    "loader=loaders.train\n",
    "class_loss=class_loss\n",
    "optimizer=optimizer\n",
    "scheduler=scheduler\n",
    "max_norm=max_norm\n",
    "epoch=epoch\n",
    "freq=visdom_freq\n",
    "ex=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, vvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "device = next(model.parameters()).device\n",
    "to_device = lambda x: x.to(device, non_blocking=True)\n",
    "loader_length = len(loader)\n",
    "train_losses = AverageMeter(device=device, length=loader_length)\n",
    "train_accs = AverageMeter(device=device, length=loader_length)\n",
    "pbar = tqdm(loader, ncols=80, desc='Training   [{:03d}]'.format(epoch))\n",
    "for i, entry in enumerate(pbar):\n",
    "    global_feats, local_feats, local_mask, scales, positions, _, _ = entry\n",
    "    global_feats, local_feats, local_mask, scales, positions = map(to_device, (global_feats, local_feats, local_mask, scales, positions))\n",
    "\n",
    "    p_logits = model(global_feats[0::3], local_feats[0::3], local_mask[0::3], scales[0::3], positions[0::3],\n",
    "        global_feats[1::3], local_feats[1::3], local_mask[1::3], scales[1::3], positions[1::3])\n",
    "    n_logits = model(global_feats[0::3], local_feats[0::3], local_mask[0::3], scales[0::3], positions[0::3],\n",
    "        global_feats[2::3], local_feats[2::3], local_mask[2::3], scales[2::3], positions[2::3])\n",
    "\n",
    "    logits = torch.cat([p_logits, n_logits], 0)\n",
    "    bsize = logits.size(0)\n",
    "    # assert (bsize % 2 == 0)\n",
    "    labels = logits.new_ones(logits.size()).float()\n",
    "    labels[(bsize//2):] = 0\n",
    "    loss = class_loss(logits, labels).mean()\n",
    "    acc = ((torch.sigmoid(logits) > 0.5).long() == labels.long()).float().mean()\n",
    "\n",
    "    ##############################################\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if max_norm > 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "    if scheduler[-1]:\n",
    "        scheduler[0].step()\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "\n",
    "    if not (i + 1) % freq:\n",
    "        step = epoch + i / loader_length\n",
    "        print('step/loss/accu/lr:', step, train_losses.last_avg.item(), train_accs.last_avg.item(), scheduler[0].get_last_lr()[0])\n",
    "\n",
    "\n",
    "if not scheduler[-1]:\n",
    "    scheduler[0].step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd =  pickle_load(osp.join(train_data_dir, train_gnd_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['easy', 'hard', 'junk', 'neg', 'provenance_entity', 'ir_order', 'img_rank_dict', 'rank_img_dict', 'r_easy', 'r_hard', 'r_junk', 'r_neg', 'r_ir_order', 'anchor_idx', 'g_easy', 'g_hard', 'g_junk', 'g_neg'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd['gnd'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSampler():\n",
    "    def __init__(self, labels, batch_size, nn_inds_path, num_candidates, gnd_data, min_pos=3):\n",
    "        self.batch_size     = batch_size\n",
    "        self.num_candidates = num_candidates\n",
    "        self.cache_nn_inds  = pickle_load(nn_inds_path)\n",
    "        self.labels = labels\n",
    "        self.gnd_data = gnd_data\n",
    "        print('nn_inds_path: ', nn_inds_path)\n",
    "        print('labels len: ', len(labels))\n",
    "        assert (len(self.cache_nn_inds) == len(labels))\n",
    "        #############################################################################\n",
    "        ## Collect valid tuples\n",
    "        valids = np.zeros_like(labels)\n",
    "        for i in range(len(self.cache_nn_inds)):\n",
    "            positives = self.gnd_data[i]['r_easy']\n",
    "            negatives = self.gnd_data[i]['r_junk']\n",
    "            if len(positives) < min_pos or len(negatives) < min_pos:\n",
    "                continue\n",
    "            valids[i] = 1\n",
    "        self.valids = np.where(valids > 0)[0]\n",
    "        self.num_samples = len(self.valids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        cands = torch.randperm(self.num_samples).tolist()\n",
    "        for i in range(len(cands)):\n",
    "            query_idx = self.valids[cands[i]]\n",
    "            anchor_idx = self.gnd_data[query_idx]['anchor_idx']\n",
    "            \n",
    "            positive_inds = self.gnd_data[query_idx]['g_easy']\n",
    "            negative_inds = self.gnd_data[query_idx]['g_junk']\n",
    "            assert(len(positive_inds) > 0)\n",
    "            assert(len(negative_inds) > 0)\n",
    "\n",
    "            random.shuffle(positive_inds)\n",
    "            random.shuffle(negative_inds)\n",
    "\n",
    "            batch.append(anchor_idx)\n",
    "            batch.append(positive_inds[0]) \n",
    "            batch.append(negative_inds[0])\n",
    "\n",
    "            if len(batch) >= self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                \n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_samples * 3 + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gnd_data  = None if train_gnd_file is None else pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "train_lines     = read_file(osp.join(train_data_dir, train_txt[1]))\n",
    "train_q_lines   = read_file(osp.join(train_data_dir, train_txt[0]))\n",
    "train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "train_q_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_q_lines]\n",
    "train_set       = FeatureDataset(train_data_dir, train_samples,   desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "query_train_set = FeatureDataset(train_data_dir, train_q_samples, desc_name, max_sequence_len, gnd_data=train_gnd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g_lines   = read_file(osp.join(train_data_dir, 'train_gallery.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42678, 1190, 42678)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines), len(train_q_lines), len(train_g_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_inds_path:  /mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/train_nn_inds_r50_gldv2.pkl\n",
      "labels len:  1190\n"
     ]
    }
   ],
   "source": [
    "#s_name = set_name\n",
    "#if s_name != '':\n",
    "#    s_name = set_name + '_'\n",
    "#def map_nnids_labels(train_data_dir, train_gnd_file, s_categories):\n",
    "#    gnd =  pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "#    selection_gallery = gnd['simlist']\n",
    "#    s_categories = s_categories.reshape(np.array(selection_gallery).shape)\n",
    "#    selection_ids_to_cat_dict = [{k: s_categories[i][k] for k in range(len(selection_gallery[i]))} for i in range(len(selection_gallery))]\n",
    "#    print(s_categories.shape)\n",
    "#\n",
    "#    return selection_ids_to_cat_dict\n",
    "#\n",
    "#s_path = train_data_dir+'/'+set_name+'_s_categories.txt'\n",
    "#s_categories = np.loadtxt(s_path, dtype='int64')\n",
    "#map_nnids_labels = map_nnids_labels(train_data_dir, train_gnd_file, s_categories)\n",
    "\n",
    "train_nn_inds = osp.join(train_data_dir, set_name + '_nn_inds_%s.pkl'%desc_name)\n",
    "gnd_data = train_set.gnd_data['gnd']\n",
    "train_sampler = TripletSampler(query_train_set.targets, batch_size, train_nn_inds, num_candidates, gnd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_inds_path =  osp.join(train_data_dir, 'training_' + s_name+'nn_inds_%s.pkl'%desc_name)\n",
    "#cache_nn_inds = torch.from_numpy(pickle_load(nn_inds_path)).long()\n",
    "#cache_nn_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sampler.valids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[595, 31140, 40131, 8225, 15391, 28880, 39535, 219, 25725, 3983, 2335, 32838, 35832, 42381, 12440, 11425, 1861, 31095, 23538, 31103, 5690, 26137, 31014, 18253, 25105, 12998, 18360, 30001, 27306, 733, 11879, 27221, 1941, 35663, 4884, 37419]\n",
      "[429, 22794, 785, 13484, 33959, 12831, 40443, 37419, 42270, 39603, 41636, 21780, 34329, 36981, 19127, 40698, 37006, 20367, 11113, 19221, 24183, 36641, 28828, 32386, 21783, 18164, 17682, 3219, 11513, 5580, 9917, 35985, 23702, 19943, 37482, 14056]\n",
      "[38680, 23938, 10102, 32433, 10127, 13220, 35209, 6999, 41424, 41393, 7461, 24469, 25571, 14362, 7154, 22330, 17711, 34982, 21162, 24393, 18583, 9846, 29882, 17941, 17351, 41191, 15640, 14616, 21447, 18324, 26109, 26405, 3519, 17540, 37771, 24411]\n",
      "[17949, 19770, 16056, 1480, 25043, 5934, 13960, 36999, 8082, 40413, 9300, 17980, 34059, 24829, 32577, 11472, 34451, 29418, 18940, 15202, 8315, 1667, 1550, 20096, 35613, 30089, 4919, 22340, 4321, 11654, 39186, 16450, 2172, 13308, 31419, 26518]\n",
      "[11036, 17486, 31955, 3126, 10335, 9382, 12151, 8130, 716, 19471, 3829, 9525, 2347, 1650, 32991, 11879, 33969, 19815, 22784, 25331, 39759, 37882, 1246, 35028, 32694, 14037, 26045, 2132, 22559, 13800, 3331, 38859, 38024, 39355, 11794, 35037]\n",
      "[11451, 9677, 6879, 18097, 10708, 41134, 11576, 4775, 27431, 38168, 39113, 14267, 35179, 14981, 719, 38788, 24078, 27307, 41145, 40687, 6950, 37672, 10419, 11955, 22956, 37030, 22525, 8842, 23115, 9717, 25916, 16578, 25420, 13515, 33064, 11592]\n",
      "[13397, 640, 28613, 5056, 17604, 23654, 7124, 26250, 15836, 38730, 33918, 18061, 33962, 20932, 33379, 16842, 32524, 39967, 26925, 2505, 4243, 16846, 17817, 20967, 37224, 2874, 17663, 21026, 38113, 33249, 14743, 24655, 18237, 32369, 32976, 24472]\n",
      "[31962, 15339, 4812, 41258, 33551, 6189, 9114, 24357, 29486, 9290, 1595, 22717, 30547, 29027, 11277, 15267, 37674, 31708, 860, 8055, 27683, 38315, 42076, 17810, 16487, 21379, 30824, 23045, 3289, 26164, 24453, 21424, 2519, 38025, 14576, 15683]\n",
      "[16979, 3148, 21303, 37111, 24412, 33130, 26339, 25543, 31785, 15378, 32405, 28366, 34365, 15096, 32537, 3848, 12684, 39559, 23065, 15861, 10891, 24480, 17520, 30957, 21497, 40688, 26632, 2217, 19222, 13164, 25244, 26598, 21529, 19834, 40310, 24596]\n",
      "[15398, 36537, 1753, 25971, 14310, 11892, 3463, 7833, 16958, 30127, 18042, 32267, 3509, 35551, 11836, 24257, 37294, 22757, 41858, 10843, 33543, 6672, 10652, 3736, 10082, 22511, 15359, 9271, 3014, 3275, 4935, 29382, 24711, 12493, 16611, 4269]\n",
      "[21264, 7463, 41817, 32373, 325, 37879, 17784, 21509, 23826, 41867, 25643, 37620, 21691, 24829, 28750, 29741, 26519, 18802, 14616, 5792, 26729, 36709, 24099, 29701, 10702, 16265, 23345, 36709, 17201, 17270, 7456, 38041, 40851, 23947, 24517, 30612]\n",
      "[33741, 29906, 16330, 32891, 32506, 14664, 35392, 1600, 20230, 38253, 23375, 4277, 32641, 18071, 32996, 10140, 23131, 1472, 30168, 18394, 31213, 29373, 25077, 32267, 9771, 6213, 35713, 23376, 10927, 36114, 24567, 37911, 20882, 12472, 8678, 19024]\n",
      "[27204, 17095, 14679, 32049, 41599, 28733, 23353, 25030, 7065, 17155, 19426, 24143, 15568, 36323, 20853, 34005, 6568, 22767, 11391, 11747, 26476, 14838, 15989, 20347, 2423, 30756, 29175, 9152, 10932, 31752, 10998, 7566, 33550, 21334, 32798, 34012]\n",
      "[31544, 16235, 17546, 10215, 6581, 12244, 40423, 13318, 25628, 16901, 25948, 776, 41634, 28190, 4133, 15833, 19093, 13725, 18854, 37720, 9020, 15089, 19332, 21578, 16463, 14494, 3348, 8227, 36208, 30708, 2282, 39230, 28196, 7769, 27110, 6435]\n",
      "[31474, 26025, 11896, 35362, 25193, 35240, 42483, 22658, 19248, 40292, 37172, 26769, 15743, 29931, 16028, 21497, 17018, 35228, 21475, 32312, 17422, 38870, 3879, 33785, 16491, 20541, 33677, 26477, 8004, 10709, 11803, 28996, 40241, 38520, 27084, 3180]\n",
      "[8990, 23692, 12028, 3560, 33946, 41569, 23762, 37124, 11883, 37099, 19191, 33077, 35998, 13059, 8145, 10987, 18329, 32948, 18577, 42127, 25613, 9092, 24038, 14381, 18985, 38231, 21960, 32769, 32721, 33270, 38802, 14189, 29385, 29526, 13631, 22495]\n",
      "[2547, 9424, 28025, 18381, 18381, 4283, 39154, 28767, 16370, 28617, 29392, 23788, 8412, 35341, 39682, 2272, 1358, 14508, 30419, 41300, 13858, 34614, 26558, 35349, 29977, 24352, 22194, 21112, 35639, 28217, 41886, 15063, 31609, 26804, 23483, 24644]\n",
      "[5653, 11799, 36280, 18131, 15560, 22477, 17220, 13819, 27826, 29458, 20050, 38351, 17088, 13177, 1905, 24503, 20615, 12584, 29453, 7682, 33766, 32609, 38749, 26329, 10215, 2417, 602, 9732, 4531, 39715, 20839, 29432, 13901, 28677, 17131, 26376]\n",
      "[30911, 1084, 37728, 29752, 40731, 14890, 32283, 35464, 24243, 10392, 8618, 1146, 24479, 27617, 36941, 14112, 15096, 1457, 24069, 21632, 17930, 23784, 29921, 27429, 7806, 10790, 18995, 17784, 11881, 7731, 3870, 20864, 7749, 259, 14051, 6285]\n",
      "[7664, 8392, 5738, 29929, 7396, 2011, 7823, 14234, 29545, 7806, 41036, 35748, 24826, 32707, 1682, 1585, 42586, 17670, 3787, 16676, 479, 25979, 5462, 7239, 8228, 29303, 31213, 20631, 15534, 18182, 23412, 13197, 15582, 38656, 29144, 12113]\n",
      "[28528, 17663, 9226, 27267, 35225, 18857, 14419, 2828, 23286, 13339, 40137, 40672, 35577, 6088, 40132, 36648, 39693, 5061, 9821, 4102, 37636, 12234, 1461, 9317, 3318, 37426, 32839, 12166, 26807, 26799, 6698, 25512, 19626, 2132, 40501, 33073]\n",
      "[15378, 37424, 42071, 41486, 15473, 9314, 1777, 1010, 20041, 36497, 19256, 5337, 36195, 18734, 7803, 6005, 30956, 16652, 18366, 31847, 6344, 28516, 5000, 16331, 12615, 32351, 19657, 7597, 17228, 6994, 18051, 17170, 7718, 26215, 34924, 35877]\n",
      "[3803, 8208, 25089, 18120, 32085, 24597, 18357, 11606, 4961, 5770, 37435, 14622, 22187, 40348, 23710, 18737, 16530, 36012, 37859, 37397, 9882, 16269, 27139, 38200, 33968, 8422, 3016, 549, 3118, 36144, 14695, 38262, 14283, 9223, 14731, 26422]\n",
      "[10472, 3902, 25374, 10281, 3945, 29267, 13825, 37200, 33440, 34839, 3063, 40022, 13060, 21596, 39997, 36439, 27803, 5080, 40708, 26610, 39107, 18069, 38097, 27809, 11677, 13259, 8039, 15131, 4266, 8453, 26958, 41107, 39703, 5159, 3838, 14990]\n",
      "[712, 27478, 4910, 19855, 15010, 11703, 36273, 9724, 5102, 246, 11788, 22699, 7639, 24327, 37729, 7804, 4, 34077, 25318, 27073, 32608, 28802, 20740, 54, 19188, 25660, 28994, 40977, 19490, 27867, 3056, 3342, 25097, 29098, 4497, 35910]\n",
      "[40512, 3049, 11599, 7385, 6544, 12017, 14612, 24893, 28567, 24989, 22715, 16077, 26544, 30672, 26179, 8622, 36934, 5436, 30939, 21504, 36793, 19698, 36333, 22761, 28504, 28959, 13619, 24144, 20948, 9144, 42655, 11170, 23935, 28691, 26273, 28486]\n",
      "[17989, 34832, 35132, 30088, 17150, 29699, 8320, 32716, 26794, 37523, 7063, 7164, 23475, 10399, 33481, 18764, 18251, 3384, 2758, 5349, 38383, 5091, 2710, 27609, 31252, 31786, 21878, 9743, 1806, 22372, 2177, 15695, 23142, 17554, 14162, 38852]\n",
      "[32586, 3537, 4767, 2627, 29880, 4659, 3006, 11003, 26746, 40279, 18200, 23780, 16826, 2147, 18570, 38792, 21844, 23951, 28146, 29511, 21432, 28973, 16209, 37739, 28223, 26557, 645, 11342, 18503, 34289, 11327, 25699, 36243, 16651, 32706, 16816]\n",
      "[8108, 19212, 20671, 24021, 5424, 19203, 24981, 166, 9471, 40023, 42292, 17633, 37310, 14268, 19904, 1859, 20831, 40735, 30088, 38755, 7372, 1403, 19563, 35709, 7124, 34911, 40169, 33853, 26852, 25537, 7079, 12720, 19838, 13253, 14641, 31192]\n",
      "[41632, 22915, 16762, 40545, 40621, 8115, 22085, 35126, 23691, 16438, 33519, 40904, 3447, 1215, 32299, 35656, 30266, 13722, 13120, 33197, 1907, 10079, 34406, 6494, 29780, 35664, 23558, 34339, 8408, 18092, 11091, 16809, 2159, 698, 15418, 23395]\n",
      "[27001, 6015, 25351, 25883, 1829, 11109, 28946, 37403, 5634, 11451, 32815, 12835, 10745, 41830, 38539, 13308, 27525, 16562, 38718, 11358, 4121, 16811, 20851, 8551, 40998, 6140, 29594, 29551, 8653, 33804, 30407, 32386, 10579, 28532, 18219, 15065]\n",
      "[42533, 26247, 4257, 31109, 1390, 2909, 1157, 42137, 10936, 27783, 21864, 29633, 10236, 31666, 39201, 34066, 30062, 6250, 24735, 13975, 641, 35151, 10652, 2307, 13189, 283, 2844, 11119, 7858, 28069, 31295, 22309, 37742, 784, 4196, 37638]\n",
      "[6003, 28636, 31325, 32593, 1656, 14246, 9572, 38864, 30513, 30497, 42160, 26938, 28349, 24808, 31250, 4653, 34165, 10923, 4504, 22374, 2186, 39954, 26263, 11153, 21729, 7566, 13006, 17467, 12241, 31548, 38835, 31921, 24506, 10789, 16185, 6349]\n",
      "[39458, 8788, 37654, 27449, 16541, 14733, 24749, 19435, 9579, 35392, 26116, 13062, 19995, 1942, 21617, 36610, 27810, 37436, 18553, 37755, 1000, 33794, 33786, 15500, 40298, 14160, 21469, 29674, 16161, 36506, 32942, 41036, 42110, 28638, 12874, 13523]\n",
      "[30252, 41109, 11134, 5038, 41775, 28601, 14578, 38711, 23505, 24888, 6105, 32829, 1510, 19472, 37438, 13229, 19521, 20865, 30197, 21188, 13465, 29867, 6171, 13093, 171, 21893, 35660, 29161, 1516, 41650, 25755, 5946, 18367, 12166, 26613, 33812]\n",
      "[1430, 9951, 69, 22086, 22865, 697, 42342, 32568, 3815, 12077, 28151, 41660, 39959, 24101, 2916, 15256, 20243, 18755, 28669, 26888, 34216, 11482, 14931, 2612, 21380, 6097, 16385, 18120, 27933, 30551, 12940, 9026, 33468, 21481, 23580, 24775]\n",
      "[32336, 23923, 27182, 5876, 27560, 35987, 19350, 10470, 38109, 30024, 2840, 5803, 31772, 40534, 30026, 26415, 18987, 37945, 33747, 37323, 22632, 10569, 20379, 13594, 19619, 33437, 5168, 40979, 32213, 5978, 14466, 4080, 33320, 19137, 29765, 6206]\n",
      "[8283, 31807, 41739, 12948, 17828, 25163, 22103, 30358, 10877, 15106, 20799, 2342, 26340, 21447, 10743, 35940, 34493, 1431, 5026, 18640, 2485, 2301, 41153, 6929, 12862, 38042, 31780, 14954, 25320, 35388, 15311, 11301, 22756, 17225, 627, 17908]\n",
      "[24257, 21294, 6846, 1590, 34062, 24337, 34814, 21312, 7517, 33906, 25436, 22648, 35863, 11571, 13024, 17220, 3028, 34016, 8260, 35825, 35143, 37165, 35665, 22515, 32057, 41057, 18701, 18513, 12753, 33423, 32816, 11338, 42513, 24800, 18514, 37246]\n",
      "[12756, 6456, 37827, 18233, 8747, 6022, 10297, 42235, 13627, 38568, 40574, 33426, 3146, 38996, 15559, 2423, 30756, 14413, 31505, 41742, 29557, 23476, 33496, 29179, 2389, 9011, 6438, 16917, 19785, 38425, 9438, 36479, 20668, 25204, 41170, 25950]\n",
      "[27134, 19671, 9564, 11113, 1702, 34367, 20887, 14441, 11015, 9343, 12902, 16600, 24463, 6846, 20955, 14616, 41791, 27266, 20973, 7835, 14000, 3027, 26199, 8907, 4003, 35189, 15211, 26433, 9704, 30194, 9122, 10154, 26837, 37187, 33144, 32376]\n",
      "[32154, 24454, 15717, 7594, 31949, 6027, 7870, 15325, 42422, 36895, 1800, 6230, 11922, 42490, 26587, 5557, 26072, 8897, 19568, 9139, 41881, 23900, 5483, 19503, 34865, 7748, 21772, 38567, 22130, 36357, 33204, 33684, 20301, 26390, 36098, 22884]\n",
      "[41645, 40581, 34649, 21323, 40244, 14895, 20258, 13651, 271, 41867, 1214, 39294, 10236, 423, 34374, 35080, 7121, 37287, 32737, 10315, 33991, 14076, 21636, 11238, 14244, 28212, 35488, 36016, 3354, 27552, 41524, 18833, 11921, 36428, 32947, 34659]\n",
      "[30617, 42485, 13021, 13698, 20043, 11177, 26268, 26735, 31761, 27331, 36200, 36745, 12976, 15073, 41778, 42201, 23720, 3792, 28532, 22993, 23325, 42653, 41839, 20305, 1988, 24177, 40099, 10262, 7805, 34754, 37358, 8380, 37231, 7814, 23166, 24364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13354, 5213, 2495, 14505, 5667, 9533, 36100, 14249, 36021, 25944, 32927, 16207, 5518, 11202, 1176, 34375, 13332, 23054, 13749, 34504, 41032, 31318, 37990, 25888, 41401, 37173, 23107, 34931, 34856, 8978, 21222, 21804, 42145, 30735, 16036, 34890]\n",
      "[12302, 3149, 34523, 41818, 31512, 6927, 24916, 32970, 3022, 35888, 12881, 11847, 22714, 3651, 33311, 20634, 22342, 3524, 15392, 38932, 12044, 18629, 40060, 19712, 22681, 21256, 14151, 19829, 19270, 12009, 13634, 39811, 32520, 10655, 6791, 26489]\n",
      "[33085, 4637, 17010, 11280, 25330, 26666, 18783, 4280, 31925, 9710, 9434, 22148, 14081, 20081, 41113, 5624, 9065, 32603, 12311, 18205, 42630, 1106, 33648, 40787, 13929, 19111, 15093, 11639, 8904, 6392, 30215, 19796, 13748, 4346, 20596, 30109]\n",
      "[15680, 32455, 30389, 5210, 37376, 4743, 31030, 15377, 16199, 25872, 11479, 40552, 17755, 20205, 26208, 32056, 5918, 17362, 2581, 30561, 33061, 6637, 24321, 3116, 32297, 4586, 23303, 33116, 4512, 28717, 24616, 21937, 4048, 27216, 41831, 15074]\n",
      "[28252, 13899, 3348, 33323, 10413, 28431, 18395, 36960, 3659, 18565, 20121, 28166, 15815, 29529, 1479, 16849, 39650, 26355, 42566, 11717, 20776, 24507, 32950, 10823, 12425, 36183, 21785, 28104, 25110, 21733, 20906, 41648, 26205, 39838, 34266, 26426]\n",
      "[26375, 19450, 8431, 41694, 35942, 32785, 41041, 20335, 5293, 18201, 41860, 25056, 28988, 36124, 40191, 27086, 25723, 11662, 10362, 24750, 14923, 7136, 10476, 5165, 16181, 30633, 10541, 37138, 24389, 13630, 28655, 34001, 29858, 19321, 40370, 17962]\n",
      "[5713, 14443, 35487, 5504, 33857, 41643, 35203, 29559, 1826, 8740, 22073, 6755, 27052, 8315, 3493, 27658, 2035, 19870, 427, 42197, 12672, 40398, 20770, 12455, 10070, 16010, 9137, 7870, 41156, 17093, 1303, 30834, 179, 24107, 6662, 22771]\n",
      "[17502, 14526, 19896, 25824, 40741, 18756, 29647, 14717, 32498, 9186, 13046, 11827, 35906, 32229, 22171, 23180, 11593, 2525, 11130, 11194, 26564, 29437, 5764, 36789, 17441, 19258, 39890, 11849, 1603, 18313, 42403, 631, 25572, 23222, 22281, 13530]\n",
      "[10875, 25378, 5367, 2847, 4576, 37805, 42282, 12847, 3672, 23637, 9654, 42230, 29937, 18100, 11217, 27970, 15902, 10306, 2806, 38864, 5580, 21722, 5840, 24817, 2255, 15028, 7531, 9252, 35552, 40972, 15168, 33953, 6724, 13047, 16608, 5458]\n",
      "[40398, 37333, 35323, 9743, 16762, 16991, 10629, 5420, 13757, 23977, 11105, 32109, 3891, 34609, 6689, 38886, 40946, 24293, 23500, 4335, 41291, 11453, 4796, 7867, 5653, 19106, 27731, 41906, 19007, 28851, 2450, 1638, 39792, 16732, 38080, 29470]\n",
      "[33420, 12278, 21247, 16593, 18199, 23085, 16019, 23101, 38897, 15049, 11748, 22905, 5526, 34666, 1464, 1183, 11047, 13390, 25812, 329, 41956, 11386, 39210, 24214, 6848, 7115, 25827, 11961, 7057, 28965, 36393, 37332, 25483, 33043, 230, 12373]\n",
      "[36033, 10328, 30738, 22156, 23013, 31198]\n"
     ]
    }
   ],
   "source": [
    "for item in train_sampler:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 662, 972)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "95*9, len(train_sampler.valids), 9*3*36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, [36033, 10328, 30738, 22156, 23013, 31198])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item), item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd['gnd'][10]['hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd['simlist'][1][6:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
