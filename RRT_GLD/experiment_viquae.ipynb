{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle, json, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import os.path as osp\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacred\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sacred import SETTINGS\n",
    "from sacred.utils import apply_backspaces_and_linefeeds\n",
    "from torch.backends import cudnn\n",
    "from torch.optim import SGD, Adam, AdamW, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.backends import cudnn\n",
    "# from visdom_logger import VisdomLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, BatchSampler\n",
    "from typing import NamedTuple, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.matcher import MatchERT\n",
    "from models.ingredient import model_ingredient, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/anaconda3/envs/rrt/lib/python3.7/site-packages/ranx/qrels_run_common.py:7: UserWarning: Sorting disabled. Assumes that you provided sorted doc_ids!\n",
      "  warnings.warn(\"Sorting disabled. Assumes that you provided sorted doc_ids!\")\n"
     ]
    }
   ],
   "source": [
    "from models.ingredient import model_ingredient, get_model\n",
    "from utils import state_dict_to_cpu, num_of_trainable_params\n",
    "from utils import pickle_load, pickle_save\n",
    "#from utils.data.utils import TripletSampler\n",
    "from utils import BinaryCrossEntropyWithLogits\n",
    "from utils.data.dataset_ingredient import data_ingredient, get_loaders\n",
    "from utils.training import train_one_epoch, evaluate_viquae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pickle_load\n",
    "from sacred import Experiment\n",
    "from utils.data.dataset_ingredient import data_ingredient, get_loaders\n",
    "from utils.data.dataset import FeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sacred.Experiment('RRT Training', ingredients=[data_ingredient, model_ingredient], interactive=True)\n",
    "# Filter backspaces and linefeeds\n",
    "SETTINGS.CAPTURE_MODE = 'sys'\n",
    "ex.captured_out_filter = apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "lr = 0.0001\n",
    "momentum = 0.\n",
    "nesterov = False\n",
    "weight_decay = 5e-4\n",
    "optim = 'adamw'\n",
    "scheduler = 'multistep'\n",
    "max_norm = 0.0\n",
    "seed = 0\n",
    "\n",
    "visdom_port = None\n",
    "visdom_freq = 100\n",
    "cpu = False  # Force training on CPU\n",
    "cudnn_flag = 'benchmark'\n",
    "temp_dir = osp.join('outputs', 'temp')\n",
    "\n",
    "no_bias_decay = False\n",
    "loss = 'bce'\n",
    "scheduler_tau = [16, 18]\n",
    "scheduler_gamma = 0.1\n",
    "\n",
    "resume = '/mnt/beegfs/home/smessoud/RerankingTransformer/RRT_GLD/rrt_gld_ckpts/r50_gldv1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " False,\n",
       " 'benchmark',\n",
       " None,\n",
       " 100,\n",
       " 'outputs/temp',\n",
       " 0,\n",
       " False,\n",
       " 0.0,\n",
       " '/mnt/beegfs/home/smessoud/RerankingTransformer/RRT_GLD/rrt_gld_ckpts/r50_gldv1.pt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, cpu, cudnn_flag, visdom_port, visdom_freq, temp_dir, seed, no_bias_decay, max_norm, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_scheduler(parameters, optim, loader_length, epochs, lr, momentum, nesterov, weight_decay, scheduler, scheduler_tau, scheduler_gamma, lr_step=None):\n",
    "    if optim == 'sgd':\n",
    "        optimizer = SGD(parameters, lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True if nesterov and momentum else False)\n",
    "    elif optim == 'adam':\n",
    "        optimizer = Adam(parameters, lr=lr, weight_decay=weight_decay) \n",
    "    else:\n",
    "        optimizer = AdamW(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    if epochs == 0:\n",
    "        scheduler = None\n",
    "        update_per_iteration = None\n",
    "    elif scheduler == 'cos':\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs * loader_length, eta_min=0.000005)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.000001)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'warmcos':\n",
    "        # warm_cosine = lambda i: min((i + 1) / 3, (1 + math.cos(math.pi * i / (epochs * loader_length))) / 2)\n",
    "        warm_cosine = lambda i: min((i + 1) / 3, (1 + math.cos(math.pi * i / epochs)) / 2)\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=warm_cosine)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'multistep':\n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=scheduler_tau, gamma=scheduler_gamma)\n",
    "        update_per_iteration = False\n",
    "    elif scheduler == 'warmstep':\n",
    "        warm_step = lambda i: min((i + 1) / 100, 1) * 0.1 ** (i // (lr_step * loader_length))\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=warm_step)\n",
    "        update_per_iteration = True\n",
    "    else:\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, epochs * loader_length)\n",
    "        update_per_iteration = True\n",
    "\n",
    "    return optimizer, (scheduler, update_per_iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss):\n",
    "    if loss == 'bce':\n",
    "        return BinaryCrossEntropyWithLogits()\n",
    "    else:\n",
    "        raise Exception('Unsupported loss {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() and not cpu else 'cpu')\n",
    "# callback = VisdomLogger(port=visdom_port) if visdom_port else None\n",
    "if cudnn_flag == 'deterministic':\n",
    "    setattr(cudnn, cudnn_flag, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tuto_viquae_tuto_r50_gldv1'\n",
    "set_name = 'tuto'\n",
    "train_txt = 'tuto.txt'\n",
    "test_txt = ('tuto_query.txt', 'tuto_selection.txt')\n",
    "train_data_dir = 'data/viquae_for_rrt'\n",
    "test_data_dir  = 'data/viquae_for_rrt'\n",
    "test_gnd_file = 'gnd_tuto.pkl'\n",
    "train_gnd_file = 'training_gnd_tuto.pkl'\n",
    "desc_name = 'r50_gldv1'\n",
    "sampler = 'triplet'\n",
    "split_char  = ';;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(desc_name, \n",
    "        train_data_dir, test_data_dir, \n",
    "        train_txt, test_txt, test_gnd_file, \n",
    "        max_sequence_len, split_char):\n",
    "    ####################################################################################################################################\n",
    "    train_lines     = read_file(osp.join(train_data_dir, train_txt))\n",
    "    train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "    train_set       = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len)\n",
    "    query_train_set = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len)\n",
    "    ####################################################################################################################################\n",
    "    test_gnd_data = None if test_gnd_file is None else pickle_load(osp.join(test_data_dir, test_gnd_file))\n",
    "    query_lines   = read_file(osp.join(test_data_dir, test_txt[0]))\n",
    "    gallery_lines = read_file(osp.join(test_data_dir, test_txt[1]))\n",
    "    query_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in query_lines]\n",
    "    gallery_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in gallery_lines]\n",
    "    gallery_set = FeatureDataset(test_data_dir, gallery_samples, desc_name, max_sequence_len)\n",
    "    query_set   = FeatureDataset(test_data_dir, query_samples,   desc_name, max_sequence_len, gnd_data=test_gnd_data)\n",
    "        \n",
    "    return (train_set, query_train_set), (query_set, gallery_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(desc_name, train_data_dir, \n",
    "    batch_size, test_batch_size, \n",
    "    num_workers, pin_memory, \n",
    "    sampler, recalls, set_name,\n",
    "    train_gnd_file,\n",
    "    num_candidates=100,):\n",
    "\n",
    "    (train_set, query_train_set), (query_set, gallery_set) = get_sets(desc_name=desc_name, \n",
    "        train_data_dir=train_data_dir, test_data_dir=train_data_dir, \n",
    "        train_txt=train_txt, test_txt=test_txt, test_gnd_file=test_gnd_file, \n",
    "        max_sequence_len=max_sequence_len, split_char=split_char)\n",
    "\n",
    "    if sampler == 'random':\n",
    "        train_sampler = BatchSampler(RandomSampler(train_set), batch_size=batch_size, drop_last=False)\n",
    "    elif sampler == 'triplet':\n",
    "        s_name = set_name\n",
    "        if s_name != '':\n",
    "            s_name = set_name + '_'\n",
    "        def map_nnids_labels(train_data_dir, train_gnd_file, s_categories):\n",
    "            gnd =  pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "            selection_gallery = gnd['simlist']\n",
    "            s_categories = s_categories.reshape(np.array(selection_gallery).shape)\n",
    "            selection_ids_to_cat_dict = [{k: s_categories[i][k] for k in range(len(selection_gallery[i]))} for i in range(len(selection_gallery))]\n",
    "\n",
    "            return selection_ids_to_cat_dict\n",
    "        \n",
    "        s_categories = np.loadtxt(train_data_dir+'/tuto_s_categories.txt', dtype='int64')\n",
    "        map_nnids_labels = map_nnids_labels(train_data_dir, train_gnd_file, s_categories)\n",
    "        train_nn_inds = osp.join(train_data_dir, 'training_' + s_name+'nn_inds_%s.pkl'%desc_name)\n",
    "        train_sampler = TripletSampler(train_set.targets, batch_size, train_nn_inds, num_candidates, map_nnids_labels)\n",
    "    else:\n",
    "        raise ValueError('Invalid choice of sampler ({}).'.format(sampler))\n",
    "    train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    query_train_loader = DataLoader(query_train_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "    query_loader   = DataLoader(query_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    gallery_loader = DataLoader(gallery_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return MetricLoaders(train=train_loader, query_train=query_train_loader, query=query_loader, gallery=gallery_loader, num_classes=len(train_set.categories),set_name=set_name), recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLoaders(NamedTuple):\n",
    "    train: DataLoader\n",
    "    num_classes: int\n",
    "    query: DataLoader\n",
    "    query_train: DataLoader\n",
    "    set_name: str = ''\n",
    "    gallery: Optional[DataLoader] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size      = 32\n",
    "test_batch_size = 32\n",
    "max_sequence_len = 500\n",
    "num_workers = 8  # number of workers used ot load the data\n",
    "pin_memory  = True  # use the pin_memory option of DataLoader \n",
    "num_candidates = 100\n",
    "recalls = [1, 5, 6, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1071, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds_path = '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/training_tuto_nn_inds_r50_gldv1.pkl'\n",
    "cache_nn_inds  = pickle_load(nn_inds_path)\n",
    "cache_nn_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_inds_path:  /mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/training_tuto_nn_inds_r50_gldv1.pkl\n",
      "labels len:  1071\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "loaders, recall_ks = get_loaders('r50_gldv1', train_data_dir, \n",
    "    batch_size, test_batch_size, \n",
    "    num_workers, pin_memory, \n",
    "    sampler, recalls, set_name, train_gnd_file,\n",
    "    num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_global_features, num_local_features, seq_len, dim_K, dim_feedforward, nhead, num_encoder_layers, dropout, activation, normalize_before):\n",
    "    return MatchERT(d_global=num_global_features, d_model=num_local_features, seq_len=seq_len, d_K=dim_K, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, activation=activation, normalize_before=normalize_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'rrt'\n",
    "num_global_features = 2048  \n",
    "num_local_features = 128  \n",
    "seq_len = 1004\n",
    "dim_K = 256\n",
    "dim_feedforward = 1024\n",
    "nhead = 4\n",
    "num_encoder_layers = 6\n",
    "dropout = 0.0 \n",
    "activation = \"relu\"\n",
    "normalize_before = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+1)\n",
    "model = get_model(num_global_features,num_local_features,seq_len,dim_K,dim_feedforward,nhead,num_encoder_layers,dropout,activation,normalize_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameters:  2243201\n"
     ]
    }
   ],
   "source": [
    "if resume is not None:\n",
    "    checkpoint = torch.load(resume, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['state'], strict=True)\n",
    "print('# of trainable parameters: ', num_of_trainable_params(model))\n",
    "class_loss = get_loss(loss)\n",
    "nn_inds_path = osp.join(loaders.query.dataset.data_dir, loaders.set_name + '_nn_inds_%s.pkl'%loaders.query.dataset.desc_name)\n",
    "cache_nn_inds = torch.from_numpy(pickle_load(nn_inds_path)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+2)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "parameters = []\n",
    "if no_bias_decay:\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() != 1]})\n",
    "    parameters.append({'params': [par for par in model.parameters() if par.dim() == 1], 'weight_decay': 0})\n",
    "else:\n",
    "    parameters.append({'params': model.parameters()})\n",
    "optimizer, scheduler = get_optimizer_scheduler(parameters=parameters, loader_length=len(loaders.train),\n",
    "                                               optim=optim, epochs=epochs, lr=lr,\n",
    "                                               momentum=momentum, nesterov=nesterov, weight_decay=weight_decay,\n",
    "                                               scheduler=scheduler, scheduler_tau=scheduler_tau, \n",
    "                                               scheduler_gamma=scheduler_gamma, lr_step=None)\n",
    "if resume is not None and checkpoint.get('optim', None) is not None:\n",
    "    optimizer.load_state_dict(checkpoint['optim'])\n",
    "    del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed+3)\n",
    "# setup partial function to simplify call\n",
    "eval_function = partial(evaluate_viquae, model=model, \n",
    "    cache_nn_inds=cache_nn_inds,\n",
    "    recall=recall_ks, query_loader=loaders.query, gallery_loader=loaders.gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = eval_function()\n",
    "# pprint(result)\n",
    "# best_val = (0, result, deepcopy(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8d23f1e810>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor epoch in range(1):\\n    if cudnn_flag == 'benchmark':\\n        setattr(cudnn, cudnn_flag, True)\\n\\n    torch.cuda.empty_cache()\\n    train_one_epoch(model=model, loader=loaders.train, class_loss=class_loss, optimizer=optimizer, scheduler=scheduler, max_norm=max_norm, epoch=epoch, freq=visdom_freq, ex=None)\\n    \\n    # validation\\n    if cudnn_flag == 'benchmark':\\n        setattr(cudnn, cudnn_flag, False)\\n    \\n    torch.cuda.empty_cache()\\n    result = eval_function()\\n    \\n    print('Validation [{:03d}]'.format(epoch)), pprint(result)\\n    #ex.log_scalar('val.map', result['map'], step=epoch + 1)\\n\\n    if result['map'] >= best_val[1]['map']:\\n        print('New best model in epoch %d.'%epoch)\\n        best_val = (epoch + 1, result, deepcopy(model.state_dict()))\\n        torch.save({'state': state_dict_to_cpu(best_val[2]), 'optim': optimizer.state_dict()}, save_name)\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for epoch in range(1):\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    train_one_epoch(model=model, loader=loaders.train, class_loss=class_loss, optimizer=optimizer, scheduler=scheduler, max_norm=max_norm, epoch=epoch, freq=visdom_freq, ex=None)\n",
    "    \n",
    "    # validation\n",
    "    if cudnn_flag == 'benchmark':\n",
    "        setattr(cudnn, cudnn_flag, False)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    result = eval_function()\n",
    "    \n",
    "    print('Validation [{:03d}]'.format(epoch)), pprint(result)\n",
    "    #ex.log_scalar('val.map', result['map'], step=epoch + 1)\n",
    "\n",
    "    if result['map'] >= best_val[1]['map']:\n",
    "        print('New best model in epoch %d.'%epoch)\n",
    "        best_val = (epoch + 1, result, deepcopy(model.state_dict()))\n",
    "        torch.save({'state': state_dict_to_cpu(best_val[2]), 'optim': optimizer.state_dict()}, save_name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines     = read_file(osp.join(train_data_dir, train_txt))\n",
    "train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "train_set       = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len)\n",
    "query_train_set = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSampler():\n",
    "    def __init__(self, labels, batch_size, nn_inds_path, num_candidates, map_nnids_labels):\n",
    "        self.batch_size     = batch_size\n",
    "        self.num_candidates = num_candidates\n",
    "        self.cache_nn_inds  = pickle_load(nn_inds_path)\n",
    "        self.labels = labels\n",
    "        self.map_nnids_labels = map_nnids_labels\n",
    "        print('nn_inds_path: ', nn_inds_path)\n",
    "        print('labels len: ', len(labels))\n",
    "        assert (len(self.cache_nn_inds) == len(labels))\n",
    "        #############################################################################\n",
    "        ## Collect valid tuples\n",
    "        valids = np.zeros_like(labels)\n",
    "        for i in range(len(self.cache_nn_inds)):\n",
    "            nnids = self.cache_nn_inds[i]\n",
    "            query_label = labels[i]\n",
    "            index_labels = np.array([map_nnids_labels[i][j] for j in nnids])\n",
    "            #index_labels = np.array([labels[j] for j in nnids])\n",
    "            positives = np.where(index_labels == query_label)[0]\n",
    "            if len(positives) < 1:\n",
    "                continue\n",
    "            valids[i] = 1\n",
    "        self.valids = valids\n",
    "        self.valids = np.where(valids > 0)[0]\n",
    "        self.num_samples = len(self.valids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        cands = torch.randperm(self.num_samples).tolist()\n",
    "        for i in range(len(cands)):\n",
    "            anchor_idx = self.valids[cands[i]]\n",
    "            anchor_label = self.labels[anchor_idx]\n",
    "            nnids = self.cache_nn_inds[anchor_idx]\n",
    "\n",
    "            positive_inds = [j for j in nnids if self.map_nnids_labels[anchor_idx][j] == anchor_label]\n",
    "            negative_inds = [j for j in nnids if self.labels[j] != anchor_label]\n",
    "            assert(len(positive_inds) > 0)\n",
    "            assert(len(negative_inds) > 0)\n",
    "\n",
    "            random.shuffle(positive_inds)\n",
    "            random.shuffle(negative_inds)\n",
    "\n",
    "            batch.append(anchor_idx)\n",
    "            batch.append(positive_inds[0]) \n",
    "            batch.append(negative_inds[0])\n",
    "\n",
    "            if len(batch) >= self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                \n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_samples * 3 + self.batch_size - 1) // self.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_inds_path:  /mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/training_tuto_nn_inds_r50_gldv1.pkl\n",
      "labels len:  1071\n"
     ]
    }
   ],
   "source": [
    "s_name = set_name\n",
    "if s_name != '':\n",
    "    s_name = set_name + '_'\n",
    "def map_nnids_labels(train_data_dir, train_gnd_file, s_categories):\n",
    "    gnd =  pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "    selection_gallery = gnd['simlist']\n",
    "    s_categories = s_categories.reshape(np.array(selection_gallery).shape)\n",
    "    selection_ids_to_cat_dict = [{k: s_categories[i][k] for k in range(len(selection_gallery[i]))} for i in range(len(selection_gallery))]\n",
    "\n",
    "    return selection_ids_to_cat_dict\n",
    "\n",
    "s_categories = np.loadtxt(train_data_dir+'/tuto_s_categories.txt', dtype='int64')\n",
    "map_nnids_labels = map_nnids_labels(train_data_dir, train_gnd_file, s_categories)\n",
    "train_nn_inds = osp.join(train_data_dir, 'training_' + s_name+'nn_inds_%s.pkl'%desc_name)\n",
    "train_sampler = TripletSampler(train_set.targets, batch_size, train_nn_inds, num_candidates, map_nnids_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1047, array([   0,    1,    2, ..., 1044, 1045, 1046]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sampler.valids), np.where(train_sampler.valids > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[267, 95, 76, 700, 16, 25, 130, 38, 33, 935, 20, 71, 773, 68, 46, 237, 42, 32, 429, 21, 2, 488, 54, 68, 1046, 56, 36, 4, 14, 46, 30, 34, 77]\n",
      "[954, 48, 70, 470, 29, 28, 144, 44, 4, 533, 4, 37, 595, 42, 45, 1005, 1, 98, 636, 52, 91, 832, 77, 65, 218, 30, 70, 573, 7, 58, 424, 23, 2]\n",
      "[549, 8, 42, 1006, 56, 19, 686, 73, 58, 734, 9, 50, 793, 44, 96, 747, 15, 48, 973, 48, 78, 848, 75, 42, 82, 52, 56, 170, 15, 55, 656, 25, 58]\n",
      "[426, 5, 98, 382, 1, 5, 158, 36, 56, 128, 99, 32, 678, 66, 70, 1032, 89, 1, 3, 93, 36, 159, 47, 40, 86, 55, 40, 280, 12, 46, 260, 94, 96]\n",
      "[1002, 77, 37, 230, 74, 77, 759, 53, 69, 32, 6, 77, 133, 84, 48, 1038, 66, 33, 289, 73, 67, 868, 51, 40, 842, 95, 22, 749, 86, 89, 1043, 69, 25]\n",
      "[240, 37, 42, 682, 9, 48, 314, 85, 68, 914, 78, 43, 434, 72, 93, 983, 82, 11, 105, 54, 44, 698, 16, 77, 542, 68, 49, 425, 44, 51, 726, 43, 18]\n",
      "[227, 74, 12, 666, 20, 32, 56, 24, 97, 101, 8, 1, 789, 63, 90, 57, 24, 12, 841, 65, 48, 421, 0, 11, 31, 17, 22, 576, 94, 2, 62, 9, 21]\n",
      "[1033, 1, 45, 897, 91, 58, 11, 7, 77, 491, 20, 16, 122, 24, 92, 249, 71, 46, 688, 29, 13, 415, 64, 95, 269, 95, 88, 724, 51, 84, 602, 65, 22]\n",
      "[88, 57, 74, 516, 98, 63, 689, 18, 22, 234, 11, 71, 537, 8, 47, 839, 77, 88, 744, 12, 23, 1013, 46, 16, 299, 9, 61, 21, 10, 58, 813, 90, 18]\n",
      "[1056, 10, 6, 402, 94, 57, 1064, 87, 20, 523, 12, 7, 860, 62, 14, 229, 11, 79, 106, 87, 42, 994, 37, 0, 1044, 8, 82, 716, 61, 12, 1059, 64, 18]\n",
      "[812, 97, 36, 814, 75, 18, 134, 10, 63, 820, 89, 94, 565, 7, 44, 2, 9, 54, 207, 26, 19, 752, 93, 33, 585, 32, 27, 142, 43, 63, 369, 59, 8]\n",
      "[482, 7, 12, 874, 64, 10, 948, 59, 68, 604, 22, 46, 8, 11, 58, 1014, 47, 73, 741, 15, 3, 141, 4, 35, 599, 36, 70, 263, 9, 88, 52, 7, 79]\n",
      "[588, 42, 14, 863, 47, 11, 717, 51, 42, 196, 47, 52, 114, 54, 58, 853, 54, 36, 758, 7, 34, 139, 8, 86, 329, 75, 19, 504, 42, 16, 116, 84, 4]\n",
      "[467, 98, 51, 522, 60, 30, 217, 85, 19, 50, 16, 3, 73, 40, 62, 1022, 50, 32, 627, 87, 87, 693, 21, 67, 253, 70, 70, 617, 22, 7, 192, 24, 58]\n",
      "[601, 65, 52, 389, 42, 34, 347, 89, 31, 259, 97, 91, 819, 83, 97, 166, 99, 15, 250, 30, 12, 1065, 59, 10, 922, 81, 9, 593, 32, 88, 322, 56, 73]\n",
      "[162, 26, 64, 664, 19, 5, 1063, 18, 34, 385, 20, 13, 884, 17, 47, 845, 86, 80, 255, 57, 26, 228, 7, 65, 1053, 48, 14, 618, 14, 52, 587, 31, 95]\n",
      "[353, 41, 87, 18, 11, 87, 910, 48, 66, 473, 86, 41, 352, 17, 68, 301, 30, 59, 188, 26, 24, 612, 65, 44, 779, 56, 92, 878, 47, 26, 248, 46, 28]\n",
      "[834, 59, 48, 972, 70, 23, 950, 24, 12, 514, 30, 55, 1012, 39, 98, 683, 74, 87, 571, 15, 72, 254, 91, 38, 14, 10, 61, 311, 89, 5, 745, 13, 97]\n",
      "[870, 55, 37, 706, 62, 89, 178, 81, 16, 81, 3, 31, 695, 9, 23, 118, 63, 33, 798, 54, 71, 115, 92, 19, 594, 42, 49, 1054, 42, 40, 222, 85, 98]\n",
      "[847, 78, 66, 554, 65, 88, 423, 30, 27, 372, 60, 30, 589, 99, 99, 691, 45, 47, 455, 0, 2, 687, 66, 25, 818, 61, 13, 829, 62, 76, 941, 41, 65]\n",
      "[449, 72, 76, 76, 43, 94, 566, 70, 92, 297, 83, 28, 396, 0, 3, 579, 93, 87, 174, 91, 78, 557, 14, 16, 988, 81, 56, 271, 84, 56, 286, 5, 93]\n",
      "[670, 40, 47, 203, 7, 70, 409, 51, 64, 374, 84, 89, 661, 64, 0, 846, 76, 60, 437, 0, 80, 223, 69, 79, 787, 45, 15, 221, 87, 73, 308, 89, 23]\n",
      "[276, 14, 35, 1034, 37, 44, 91, 92, 23, 355, 36, 52, 964, 18, 72, 803, 58, 84, 443, 52, 73, 199, 29, 15, 801, 66, 25, 195, 31, 49, 1000, 9, 65]\n",
      "[913, 80, 48, 173, 99, 47, 152, 29, 77, 536, 33, 29, 644, 46, 40, 27, 58, 64, 824, 75, 90, 534, 72, 19, 313, 80, 49, 680, 25, 17, 783, 51, 13]\n",
      "[685, 66, 79, 956, 96, 2, 1018, 12, 31, 332, 75, 42, 312, 83, 6, 68, 93, 19, 887, 84, 23, 995, 95, 94, 296, 6, 81, 450, 51, 68, 761, 7, 91]\n",
      "[788, 77, 73, 35, 13, 66, 45, 44, 10, 757, 51, 3, 172, 91, 22, 400, 64, 85, 270, 23, 32, 940, 40, 33, 527, 38, 92, 474, 40, 99, 381, 62, 42]\n",
      "[336, 75, 24, 808, 63, 97, 546, 86, 96, 462, 51, 58, 797, 67, 39, 991, 60, 23, 367, 97, 41, 241, 75, 28, 494, 96, 19, 981, 86, 3, 125, 76, 37]\n",
      "[976, 76, 39, 1067, 69, 18, 179, 7, 96, 251, 70, 42, 879, 44, 24, 881, 84, 9, 719, 33, 47, 112, 16, 6, 872, 68, 94, 379, 42, 82, 782, 69, 38]\n",
      "[518, 17, 34, 99, 57, 7, 830, 57, 49, 835, 85, 90, 672, 9, 7, 252, 69, 42, 187, 35, 71, 931, 76, 95, 265, 97, 24, 331, 34, 37, 54, 28, 34]\n",
      "[850, 48, 54, 851, 92, 4, 641, 46, 49, 147, 67, 77, 257, 35, 94, 920, 18, 98, 619, 1, 29, 261, 20, 91, 1031, 42, 63, 96, 89, 46, 1045, 99, 53]\n",
      "[157, 47, 50, 211, 44, 78, 83, 85, 16, 338, 68, 92, 341, 35, 36, 397, 94, 62, 388, 97, 70, 321, 85, 62, 512, 29, 93, 756, 21, 0, 630, 87, 5]\n",
      "[459, 53, 94, 955, 7, 32, 484, 10, 99, 796, 70, 27, 419, 26, 69, 528, 1, 18, 790, 74, 85, 377, 47, 83, 284, 94, 90, 247, 27, 6, 216, 26, 12]\n",
      "[804, 53, 69, 439, 64, 14, 608, 86, 90, 906, 10, 56, 958, 17, 74, 180, 99, 25, 942, 26, 56, 461, 70, 13, 292, 3, 12, 375, 60, 36, 508, 1, 79]\n",
      "[937, 92, 79, 481, 83, 48, 209, 29, 57, 547, 1, 60, 575, 26, 33, 1037, 65, 19, 663, 17, 72, 38, 14, 71, 418, 20, 42, 236, 62, 50, 776, 77, 23]\n",
      "[590, 48, 87, 22, 53, 49, 989, 95, 48, 822, 53, 67, 679, 65, 23, 525, 83, 77, 574, 64, 44, 213, 35, 83, 521, 35, 47, 458, 53, 46, 471, 29, 11]\n",
      "[505, 31, 28, 460, 23, 60, 1050, 47, 55, 489, 16, 41, 345, 74, 92, 177, 81, 60, 709, 16, 55, 291, 84, 61, 278, 48, 3, 5, 34, 93, 33, 54, 92]\n",
      "[900, 67, 13, 320, 62, 99, 406, 41, 59, 445, 55, 43, 960, 96, 58, 552, 28, 93, 131, 45, 42, 339, 34, 46, 980, 68, 0, 452, 20, 6, 792, 55, 6]\n",
      "[1030, 36, 46, 71, 92, 16, 654, 7, 26, 945, 21, 50, 212, 38, 22, 310, 83, 14, 205, 22, 57, 701, 57, 9, 161, 93, 27, 515, 8, 47, 939, 85, 71]\n",
      "[979, 82, 79, 917, 13, 21, 923, 14, 36, 610, 95, 22, 326, 4, 84, 394, 60, 48, 412, 41, 6, 722, 30, 31, 727, 32, 51, 483, 83, 37, 616, 16, 66]\n",
      "[391, 1, 9, 817, 95, 77, 376, 91, 97, 129, 50, 35, 949, 57, 4, 543, 16, 74, 520, 79, 15, 380, 7, 16, 510, 87, 18, 479, 75, 36, 631, 87, 83]\n",
      "[856, 84, 54, 226, 70, 27, 507, 11, 58, 694, 23, 25, 772, 43, 15, 621, 14, 67, 735, 15, 79, 511, 63, 75, 556, 6, 89, 866, 44, 96, 225, 96, 55]\n",
      "[417, 23, 33, 643, 54, 24, 167, 72, 59, 603, 94, 24, 446, 64, 53, 34, 93, 19, 411, 14, 10, 325, 80, 93, 907, 79, 84, 535, 12, 52, 330, 33, 64]\n",
      "[660, 64, 24, 569, 21, 53, 1021, 73, 27, 540, 28, 72, 294, 84, 43, 838, 52, 40, 597, 88, 7, 690, 9, 6, 541, 75, 12, 403, 62, 21, 165, 90, 95]\n",
      "[963, 20, 44, 61, 29, 3, 1051, 88, 83, 64, 8, 74, 185, 0, 24, 160, 80, 88, 513, 87, 55, 476, 40, 95, 739, 6, 31, 1003, 45, 66, 1061, 69, 54]\n",
      "[974, 23, 24, 646, 75, 51, 957, 49, 45, 622, 49, 88, 283, 94, 15, 85, 15, 57, 944, 20, 79, 743, 91, 33, 350, 1, 9, 544, 27, 20, 883, 69, 51]\n",
      "[202, 22, 58, 877, 67, 36, 775, 77, 8, 635, 50, 1, 110, 41, 55, 74, 46, 99, 568, 94, 11, 238, 42, 31, 48, 96, 58, 614, 17, 32, 657, 22, 25]\n",
      "[363, 60, 34, 837, 80, 54, 652, 21, 57, 886, 73, 80, 246, 74, 23, 103, 23, 25, 171, 99, 40, 655, 48, 96, 169, 0, 98, 763, 51, 97, 444, 62, 3]\n",
      "[918, 82, 76, 153, 89, 17, 738, 13, 25, 150, 8, 83, 342, 41, 75, 12, 4, 82, 953, 20, 1, 932, 69, 93, 943, 97, 64, 572, 27, 15, 894, 91, 65]\n",
      "[921, 78, 66, 309, 6, 97, 754, 47, 11, 548, 1, 49, 42, 59, 98, 398, 90, 24, 628, 70, 34, 999, 44, 49, 904, 0, 41, 926, 80, 39, 368, 58, 41]\n",
      "[840, 74, 83, 970, 48, 65, 858, 85, 13, 625, 87, 93, 871, 43, 76, 427, 2, 10, 811, 76, 80, 364, 84, 54, 243, 62, 24, 647, 98, 92, 828, 50, 19]\n",
      "[1048, 82, 85, 435, 46, 77, 290, 73, 43, 428, 0, 13, 668, 98, 24, 993, 69, 34, 702, 57, 43, 87, 41, 33, 63, 8, 23, 93, 44, 14, 526, 91, 25]\n",
      "[499, 53, 68, 1016, 60, 33, 102, 81, 78, 164, 89, 69, 609, 34, 51, 506, 49, 78, 387, 40, 17, 356, 36, 3, 704, 58, 18, 295, 61, 15, 1015, 91, 73]\n",
      "[892, 84, 40, 416, 9, 7, 795, 54, 4, 413, 94, 14, 581, 93, 22, 503, 9, 21, 591, 92, 5, 497, 31, 12, 893, 99, 69, 624, 70, 53, 699, 89, 4]\n",
      "[15, 8, 37, 755, 85, 43, 264, 20, 98, 323, 56, 81, 453, 98, 8, 303, 9, 30, 43, 1, 97, 992, 68, 85, 915, 48, 68, 784, 72, 46, 201, 24, 64]\n",
      "[1066, 8, 60, 7, 9, 67, 433, 91, 36, 1026, 74, 26, 266, 17, 55, 154, 29, 8, 279, 12, 77, 859, 94, 88, 720, 47, 22, 730, 24, 57, 946, 39, 50]\n",
      "[563, 63, 89, 855, 61, 25, 59, 0, 80, 977, 1, 20, 393, 48, 49, 677, 13, 48, 337, 94, 27, 183, 36, 36, 714, 16, 23, 1035, 8, 16, 117, 17, 65]\n",
      "[405, 51, 16, 538, 91, 88, 10, 1, 69, 737, 86, 20, 986, 82, 70, 182, 72, 21, 324, 59, 52, 1042, 10, 94, 135, 50, 69, 778, 41, 78, 532, 8, 76]\n",
      "[607, 49, 58, 39, 2, 1, 1024, 76, 91, 947, 40, 37, 753, 86, 20, 1041, 87, 17, 235, 37, 37, 1058, 48, 4, 899, 60, 13, 975, 69, 51, 919, 17, 39]\n",
      "[966, 58, 70, 100, 91, 65, 1028, 46, 88, 962, 12, 73, 1010, 47, 17, 1069, 58, 81, 485, 75, 11, 611, 1, 63, 662, 17, 63, 760, 6, 25, 882, 78, 68]\n",
      "[477, 40, 11, 1040, 82, 85, 349, 17, 34, 873, 48, 11, 340, 34, 3, 6, 99, 34, 404, 85, 70, 72, 43, 64, 359, 7, 59, 51, 99, 71, 786, 72, 99]\n",
      "[306, 78, 82, 770, 57, 12, 28, 13, 41, 113, 92, 44, 560, 94, 76, 861, 79, 75, 665, 18, 80, 951, 49, 54, 1, 43, 93, 231, 73, 64, 857, 52, 7]\n",
      "[304, 62, 59, 718, 32, 95, 197, 33, 54, 903, 60, 22, 232, 26, 44, 447, 90, 91, 490, 54, 59, 729, 32, 15, 732, 31, 67, 94, 93, 70, 24, 14, 45]\n",
      "[733, 68, 60, 333, 35, 16, 319, 82, 30, 1049, 99, 48, 9, 16, 83, 175, 73, 59, 354, 89, 90, 629, 87, 56, 156, 26, 27, 149, 67, 2, 501, 13, 39]\n",
      "[19, 3, 33, 193, 36, 46, 120, 17, 61, 836, 88, 48, 1070, 18, 79, 168, 44, 38, 395, 49, 79, 181, 80, 48, 242, 95, 48, 746, 99, 81, 924, 83, 44]\n",
      "[408, 6, 91, 615, 60, 20, 109, 54, 58, 137, 38, 6, 190, 54, 94, 990, 82, 55, 558, 15, 82, 200, 36, 33, 769, 60, 64, 864, 48, 66, 95, 54, 61]\n",
      "[37, 2, 89, 224, 96, 82, 206, 25, 82, 244, 93, 54, 938, 39, 77, 833, 94, 19, 138, 38, 96, 908, 14, 7, 650, 48, 62, 215, 26, 97, 151, 81, 20]\n",
      "[823, 50, 1, 697, 16, 97, 442, 27, 38, 555, 76, 64, 155, 99, 63, 821, 75, 44, 529, 7, 2, 561, 73, 73, 880, 48, 6, 466, 90, 0, 1008, 69, 33]\n",
      "[598, 51, 28, 328, 41, 22, 696, 18, 76, 539, 27, 28, 58, 24, 90, 891, 73, 20, 592, 32, 32, 432, 13, 26, 285, 12, 13, 936, 58, 31, 277, 8, 2]\n",
      "[378, 93, 44, 912, 8, 89, 1060, 48, 53, 335, 68, 50, 145, 43, 3, 930, 21, 1, 809, 49, 50, 765, 21, 90, 448, 4, 35, 651, 73, 17, 305, 81, 43]\n",
      "[25, 91, 74, 282, 11, 7, 692, 21, 59, 495, 87, 18, 933, 57, 24, 288, 73, 69, 902, 67, 98, 17, 7, 89, 1029, 14, 89, 674, 74, 13, 351, 1, 12]\n",
      "[852, 78, 16, 667, 18, 88, 124, 80, 21, 740, 85, 91, 245, 62, 70, 422, 48, 34, 29, 4, 45, 414, 49, 77, 997, 94, 16, 49, 16, 96, 707, 33, 52]\n",
      "[639, 36, 58, 1020, 74, 30, 1052, 41, 69, 1001, 40, 74, 586, 48, 52, 191, 35, 51, 1047, 63, 15, 431, 86, 98, 468, 21, 40, 136, 4, 39, 849, 67, 13]\n",
      "[1019, 76, 32, 1055, 56, 0, 362, 8, 47, 420, 26, 86, 606, 32, 88, 370, 84, 37, 401, 65, 71, 681, 27, 47, 41, 7, 98, 348, 1, 77, 768, 58, 17]\n",
      "[430, 58, 1, 98, 83, 60, 274, 48, 46, 649, 22, 14, 268, 17, 85, 1068, 85, 34, 163, 77, 73, 46, 2, 79, 965, 63, 10, 807, 47, 0, 1036, 65, 60]\n",
      "[298, 5, 81, 669, 18, 56, 498, 63, 54, 805, 76, 79, 89, 81, 1, 275, 14, 7, 189, 54, 68, 111, 96, 17, 1009, 52, 0, 456, 64, 58, 140, 8, 74]\n",
      "[262, 9, 84, 104, 3, 66, 799, 75, 5, 559, 98, 86, 233, 7, 37, 802, 75, 68, 493, 8, 72, 20, 3, 54, 785, 47, 23, 390, 42, 75, 148, 67, 22]\n",
      "[346, 17, 13, 65, 93, 91, 69, 92, 38, 640, 75, 82, 911, 16, 52, 438, 14, 92, 70, 95, 22, 146, 47, 99, 220, 30, 1, 925, 11, 59, 66, 86, 88]\n",
      "[26, 96, 92, 626, 58, 29, 44, 17, 86, 637, 54, 26, 127, 76, 57, 764, 52, 90, 715, 82, 21, 875, 43, 59, 968, 70, 94, 952, 7, 1, 47, 16, 68]\n",
      "[502, 9, 86, 143, 40, 38, 736, 86, 3, 451, 20, 99, 315, 85, 93, 708, 60, 89, 676, 66, 60, 890, 73, 57, 108, 81, 31, 767, 58, 3, 711, 52, 4]\n",
      "[862, 67, 12, 985, 82, 93, 684, 77, 29, 287, 6, 89, 998, 56, 57, 126, 77, 3, 762, 21, 75, 500, 53, 80, 60, 0, 79, 204, 47, 14, 480, 34, 23]\n",
      "[865, 56, 49, 671, 1, 5, 366, 60, 49, 888, 73, 97, 867, 55, 96, 642, 29, 7, 582, 87, 59, 869, 58, 13, 613, 34, 19, 524, 73, 36, 486, 54, 59]\n",
      "[208, 25, 99, 365, 97, 63, 92, 84, 13, 978, 97, 39, 1062, 41, 12, 723, 17, 89, 75, 43, 20, 721, 17, 27, 436, 64, 48, 967, 99, 99, 399, 9, 80]\n",
      "[492, 43, 93, 806, 73, 26, 531, 72, 51, 638, 52, 74, 281, 5, 47, 373, 11, 78, 53, 6, 22, 90, 91, 62, 67, 89, 34, 383, 8, 99, 392, 15, 71]\n",
      "[472, 40, 85, 816, 64, 73, 258, 57, 77, 361, 8, 77, 1011, 39, 4, 132, 99, 22, 725, 51, 52, 570, 86, 40, 530, 39, 71, 731, 68, 93, 343, 33, 95]\n",
      "[509, 63, 33, 16, 95, 33, 794, 42, 96, 440, 55, 6, 519, 8, 84, 307, 19, 72, 454, 3, 1, 463, 30, 77, 13, 7, 72, 844, 66, 64, 186, 73, 47]\n",
      "[36, 44, 28, 121, 24, 38, 371, 92, 36, 386, 7, 98, 464, 23, 39, 119, 63, 95, 1025, 10, 89, 1039, 18, 7, 748, 4, 23, 895, 91, 97, 929, 21, 77]\n",
      "[214, 96, 94, 876, 45, 51, 40, 93, 10, 1023, 60, 4, 826, 64, 95, 210, 9, 56, 777, 60, 73, 550, 78, 37, 675, 29, 21, 302, 85, 45, 1007, 36, 53]\n",
      "[901, 4, 9, 545, 65, 96, 645, 76, 56, 551, 17, 54, 457, 13, 13, 843, 82, 95, 673, 50, 26, 97, 85, 77, 605, 32, 57, 658, 3, 43, 854, 96, 44]\n",
      "[553, 30, 77, 487, 43, 45, 751, 47, 17, 831, 81, 95, 194, 6, 74, 239, 95, 38, 703, 58, 34, 712, 82, 78, 1004, 5, 2, 909, 82, 92, 969, 23, 54]\n",
      "[961, 96, 59, 318, 3, 26, 742, 98, 22, 780, 56, 79, 1027, 73, 46, 80, 51, 42, 984, 68, 69, 889, 84, 87, 959, 21, 38, 198, 9, 87, 971, 5, 22]\n",
      "[659, 3, 75, 928, 19, 73, 750, 6, 79, 791, 76, 42, 600, 62, 21, 55, 84, 91, 578, 92, 24, 781, 49, 5, 293, 78, 94, 982, 68, 84, 885, 55, 88]\n",
      "[360, 8, 84, 827, 53, 84, 815, 67, 32, 176, 92, 10, 256, 57, 55, 384, 7, 97, 344, 68, 56, 896, 91, 37, 996, 69, 43, 317, 84, 75, 465, 26, 86]\n",
      "[916, 17, 74, 184, 91, 8, 316, 0, 14, 300, 7, 19, 441, 29, 92, 219, 30, 80, 334, 95, 87, 596, 42, 24, 1057, 10, 52, 567, 43, 43, 410, 1, 52]\n",
      "[825, 77, 68, 898, 68, 45, 517, 86, 43, 564, 79, 3, 648, 79, 32, 84, 44, 56, 800, 55, 61, 580, 92, 50, 987, 94, 51, 774, 51, 24, 710, 51, 65]\n",
      "[620, 14, 11, 934, 41, 5, 407, 83, 12, 107, 41, 58, 653, 6, 43, 1017, 10, 69, 713, 61, 34, 771, 57, 38, 496, 0, 85, 728, 40, 49, 23, 1, 70]\n",
      "[272, 84, 22, 562, 74, 17]\n"
     ]
    }
   ],
   "source": [
    "for item in train_sampler:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item in train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
