{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import pickle_save, pickle_load\n",
    "from utils.data.delf import datum_io\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacred\n",
    "from sacred import SETTINGS\n",
    "from sacred.utils import apply_backspaces_and_linefeeds\n",
    "from numpy import linalg as LA\n",
    "from utils import pickle_load, pickle_save\n",
    "#from utils.revisited import compute_metrics\n",
    "from utils.data.delf import datum_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = sacred.Experiment('Prepare Top-K (VIQUAE FOR RTT)', interactive=True)\n",
    "# Filter backspaces and linefeeds\n",
    "SETTINGS.CAPTURE_MODE = 'sys'\n",
    "ex.captured_out_filter = apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'r50_gldv1'\n",
    "set_name = 'test'\n",
    "gnd_name = 'gnd_roxford5k.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'oxford5k'\n",
    "data_dir = osp.join('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aqe = False\n",
    "aqe_params = {'k': 2, 'alpha': 0.3}\n",
    "\n",
    "save_nn_inds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, 'test_query.txt')) as fid:\n",
    "    query_lines   = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(data_dir, set_name+'_gallery.txt')) as fid:\n",
    "    gallery_lines = fid.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 522.72it/s]\n"
     ]
    }
   ],
   "source": [
    "query_feats = []\n",
    "for i in tqdm(range(len(query_lines))):\n",
    "    name = osp.splitext(osp.basename(query_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, 'delg_' + feature_name, name + '.delg_global')\n",
    "    query_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_feats = np.stack(query_feats, axis=0)\n",
    "query_feats = query_feats / LA.norm(query_feats, axis=-1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [00:09<00:00, 551.20it/s]\n"
     ]
    }
   ],
   "source": [
    "index_feats = []\n",
    "for i in tqdm(range(len(gallery_lines))):\n",
    "    name = osp.splitext(osp.basename(gallery_lines[i].split(';;')[0]))[0]\n",
    "    path = osp.join(data_dir, 'delg_' + feature_name, name + '.delg_global')\n",
    "    index_feats.append(datum_io.ReadFromFile(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_feats = np.stack(index_feats, axis=0)\n",
    "index_feats = index_feats / LA.norm(index_feats, axis=-1)[:, None]\n",
    "\n",
    "sims = np.matmul(query_feats, index_feats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4993, 2048), (70, 2048), (70, 4993))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_feats.shape, query_feats.shape, sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_aqe:\n",
    "    alpha = aqe_params['alpha']\n",
    "    nn_inds = np.argsort(-sims, -1)\n",
    "    query_aug = deepcopy(query_feats)\n",
    "    for i in range(len(query_feats)):\n",
    "        new_q = [query_feats[i]]\n",
    "        for j in range(aqe_params['k']):\n",
    "            nn_id = nn_inds[i, j]\n",
    "            weight = sims[i, nn_id] ** aqe_params['alpha']\n",
    "            new_q.append(weight * index_feats[nn_id])\n",
    "        new_q = np.stack(new_q, 0)\n",
    "        new_q = np.mean(new_q, axis=0)\n",
    "        query_aug[i] = new_q/LA.norm(new_q, axis=-1)\n",
    "    sims = np.matmul(query_aug, index_feats.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_inds = np.argsort(-sims, -1)\n",
    "nn_dists = deepcopy(sims)\n",
    "for i in range(query_feats.shape[0]):\n",
    "    for j in range(index_feats.shape[0]):\n",
    "        nn_dists[i, j] = sims[i, nn_inds[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 4993), (70, 4993), (70, 4993))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.shape, nn_dists.shape, sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 4993, (4993, 2048))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feats.shape[0], index_feats.shape[0], index_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/oxford5k/nn_inds_r50_gldv1.pkl\n"
     ]
    }
   ],
   "source": [
    "if save_nn_inds:\n",
    "    output_path = osp.join(data_dir, 'nn_inds_%s.pkl' % feature_name)\n",
    "    print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(ranks, nres):\n",
    "    \"\"\"\n",
    "    Computes average precision for given ranked indexes.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    ranks : zerro-based ranks of positive images\n",
    "    nres  : number of positive images\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ap    : average precision\n",
    "    \"\"\"\n",
    "\n",
    "    # number of images ranked by the system\n",
    "    nimgranks = len(ranks)\n",
    "\n",
    "    # accumulate trapezoids in PR-plot\n",
    "    ap = 0\n",
    "\n",
    "    recall_step = 1. / nres\n",
    "\n",
    "    for j in np.arange(nimgranks):\n",
    "        rank = ranks[j]\n",
    "\n",
    "        if rank == 0:\n",
    "            precision_0 = 1.\n",
    "        else:\n",
    "            precision_0 = float(j) / rank\n",
    "\n",
    "        precision_1 = float(j + 1) / (rank + 1)\n",
    "\n",
    "        ap += (precision_0 + precision_1) * recall_step / 2.\n",
    "\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map(ranks, gnd, kappas=[]):\n",
    "    \"\"\"\n",
    "    Computes the mAP for a given set of returned results.\n",
    "\n",
    "         Usage: \n",
    "           map = compute_map (ranks, gnd) \n",
    "                 computes mean average precsion (map) only\n",
    "        \n",
    "           map, aps, pr, prs = compute_map (ranks, gnd, kappas) \n",
    "                 computes mean average precision (map), average precision (aps) for each query\n",
    "                 computes mean precision at kappas (pr), precision at kappas (prs) for each query\n",
    "        \n",
    "         Notes:\n",
    "         1) ranks starts from 0, ranks.shape = db_size X #queries\n",
    "         2) The junk results (e.g., the query itself) should be declared in the gnd stuct array\n",
    "         3) If there are no positive images for some query, that query is excluded from the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    map = 0.\n",
    "    nq = len(gnd) # number of queries\n",
    "    aps = np.zeros(nq)\n",
    "    pr = np.zeros(len(kappas))\n",
    "    prs = np.zeros((nq, len(kappas)))\n",
    "    nempty = 0\n",
    "\n",
    "    for i in np.arange(nq):\n",
    "        qgnd = np.array(gnd[i]['ok'])\n",
    "\n",
    "        # no positive images, skip from the average\n",
    "        if qgnd.shape[0] == 0:\n",
    "            aps[i] = float('nan')\n",
    "            prs[i, :] = float('nan')\n",
    "            nempty += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            qgndj = np.array(gnd[i]['junk'])\n",
    "        except:\n",
    "            qgndj = np.empty(0)\n",
    "\n",
    "        # sorted positions of positive and junk images (0 based)\n",
    "        pos  = np.arange(ranks.shape[0])[np.in1d(ranks[:,i], qgnd)]\n",
    "        junk = np.arange(ranks.shape[0])[np.in1d(ranks[:,i], qgndj)]\n",
    "\n",
    "        k = 0\n",
    "        ij = 0\n",
    "        if len(junk):\n",
    "            # decrease positions of positives based on the number of\n",
    "            # junk images appearing before them\n",
    "            ip = 0\n",
    "            while (ip < len(pos)):\n",
    "                while (ij < len(junk) and pos[ip] > junk[ij]):\n",
    "                    k += 1\n",
    "                    ij += 1\n",
    "                pos[ip] = pos[ip] - k\n",
    "                ip += 1\n",
    "\n",
    "        # compute ap\n",
    "        ap = compute_ap(pos, len(qgnd))\n",
    "        map = map + ap\n",
    "        aps[i] = ap\n",
    "\n",
    "        # compute precision @ k\n",
    "        pos += 1 # get it to 1-based\n",
    "        for j in np.arange(len(kappas)):\n",
    "            kq = min(max(pos), kappas[j]); \n",
    "            prs[i, j] = (pos <= kq).sum() / kq\n",
    "        pr = pr + prs[i, :]\n",
    "\n",
    "    map = map / (nq - nempty)\n",
    "    pr = pr / (nq - nempty)\n",
    "\n",
    "    return map, aps, pr, prs, nempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset, ranks, gnd, kappas=[1, 5, 10]):\n",
    "    print(ranks.shape)\n",
    "    \n",
    "    # old evaluation protocol\n",
    "    if dataset.startswith('classic'):\n",
    "        map, aps, _, _ = compute_map(ranks, gnd)\n",
    "        out = {'map': np.around(map*100, decimals=3)}\n",
    "        print('>> {}: mAP {:.2f}'.format(dataset, out['map']))\n",
    "\n",
    "    # new evaluation protocol\n",
    "    elif dataset.startswith('revisited'):\n",
    "        \n",
    "        #gnd_t = []\n",
    "        #for i in range(len(gnd)):\n",
    "        #    g = {}\n",
    "        #    g['ok'] = np.concatenate([gnd[i]['easy']])\n",
    "        #    g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['hard']])\n",
    "        #    gnd_t.append(g)\n",
    "        #mapE, apsE, mprE, prsE = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "        #gnd_t = []\n",
    "        #for i in range(len(gnd)):\n",
    "        #    g = {}\n",
    "        #    g['ok'] = np.concatenate([gnd[i]['easy'], gnd[i]['hard']])\n",
    "        #    g['junk'] = np.concatenate([gnd[i]['junk']])\n",
    "        #    gnd_t.append(g)\n",
    "        #mapM, apsM, mprM, prsM = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "        gnd_t = []\n",
    "        for i in range(len(gnd)):\n",
    "            g = {}\n",
    "            g['ok'] = np.concatenate([gnd[i]['hard']])\n",
    "            g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['easy']])\n",
    "            gnd_t.append(g)\n",
    "        mapH, apsH, mprH, prsH, nempty = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "\n",
    "        out = {\n",
    "            #'E_map': np.around(mapE*100, decimals=2),\n",
    "            #'M_map': np.around(mapM*100, decimals=2),\n",
    "            'H_map': np.around(mapH*100, decimals=2),\n",
    "            #'E_mp':  np.around(mprE*100, decimals=2),\n",
    "            #'M_mp':  np.around(mprM*100, decimals=2),\n",
    "            'H_mp':  np.around(mprH*100, decimals=2),\n",
    "        }\n",
    "\n",
    "        #print('>> {}: mAP E: {}, M: {}, H: {}'.format(dataset, out['E_map'], out['M_map'], out['H_map']))\n",
    "        print('>> {}: mAP H: {}'.format(dataset, out['H_map']))\n",
    "        #print('>> {}: mP@k{} E: {}, M: {}, H: {}'.format(dataset, kappas, out['E_mp'], out['M_mp'], out['H_mp']))\n",
    "        print('>> {}: mP@k{} H: {}'.format(dataset, kappas, out['H_mp']))\n",
    "\n",
    "    return out, mapH, apsH, mprH, prsH, nempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, gnd_name))\n",
    "len(gnd_data['gnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4993, 70)\n",
      ">> revisited: mAP H: 45.11\n",
      ">> revisited: mP@k[1, 5, 10] H: [85.71 72.29 60.14]\n"
     ]
    }
   ],
   "source": [
    "out, mapH, apsH, mprH, prsH, nempty  =compute_metrics('revisited', nn_inds.T, gnd_data['gnd'], kappas=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45108796000449053, array([0.85714286, 0.72285714, 0.60142857]), 0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapH, mprH, nempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3829, 3152,  607, ..., 3800, 4026, 3246])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.T[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gnd_data['gnd'][10]['hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "run_dict = {}\n",
    "for i in range(nn_inds.shape[0]):\n",
    "    q_str = 'q_' + str(i)\n",
    "    \n",
    "    qrels_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in gnd_data['gnd'][i]['hard']])\n",
    "    run_dict[q_str] = dict([('d_' + str(i) + '_' + str(key), 1) for key in nn_inds.T[:,i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run\n",
    "\n",
    "qrels = Qrels(qrels_dict)\n",
    "run = Run(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': 0.20006625392442232,\n",
       " 'map@1': 0.030317794838342786,\n",
       " 'map@5': 0.0949393884202708,\n",
       " 'map@10': 0.10773165740047304,\n",
       " 'mrr': 0.23435308009830536,\n",
       " 'mrr@1': 0.07142857142857142,\n",
       " 'mrr@5': 0.19309523809523807,\n",
       " 'mrr@10': 0.21769274376417233,\n",
       " 'f1@1': 0.03179706230553688}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ranx import evaluate\n",
    "\n",
    "evaluate(qrels, run, [\"map\", \"map@1\", \"map@5\", \"map@10\", \"mrr\", \"mrr@1\", \"mrr@5\", \"mrr@10\", \"f1@1\"])\n",
    "#>>> {\"map@5\": 0.6416, \"mrr\": 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
