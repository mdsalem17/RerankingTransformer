{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate, compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? compare\n",
    "#? evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle, json, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_load(path):\n",
    "    with open(path, 'r') as fid:\n",
    "        data_ = json.load(fid)\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'viquae_for_rrt'\n",
    "delg_dir = osp.join('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python', 'delg')\n",
    "data_dir = osp.join(delg_dir, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_100\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_200\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_300\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_400\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_500\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_600\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_700\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_800\r\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/dev_run_dict_900\r\n"
     ]
    }
   ],
   "source": [
    "!ls $delg_dir/dev_run_dict_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = Qrels.from_file(osp.join(delg_dir, 'tuto_qrels_dict'), kind=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "max_sequence_len = [100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "max_sequence_len = [500, 800]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/tuto_run_dict_500\n",
      "/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/tuto_run_dict_800\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for length in max_sequence_len:\n",
    "    filename = osp.join(delg_dir, 'tuto_run_dict_'+str(length))\n",
    "    print(filename)\n",
    "    run_dict = json_load(filename)\n",
    "    runs.append(Run(run_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"map\", \"mrr\", \"precision\", \"hit_rate\", \"recall\"]\n",
    "kappas  = [1, 5, 10]\n",
    "m_list  = [metric for metric in metrics]\n",
    "\n",
    "for i in range(len(kappas)):\n",
    "    m_list.extend([metric+'@'+str(kappas[i]) for metric in metrics])\n",
    "\n",
    "metrics = [element for element in m_list if element not in ['precision',  'hit_rate',  'recall',  'map@1',  'mrr@1', 'hit_rate@1', 'map@5',  'mrr@5',  'map@10',  'mrr@10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels.save('zut_qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;27mdata\u001b[0m/\r\n",
      "\u001b[38;5;27mdelg_scripts\u001b[0m/\r\n",
      "evaluate_revisited.ipynb\r\n",
      "evaluate_revisited.py\r\n",
      "evaluate_viquae.ipynb\r\n",
      "evaluate_viquae.py\r\n",
      "experiment_new_viquae-Copy1.ipynb\r\n",
      "experiment_new_viquae.ipynb\r\n",
      "experiment.py\r\n",
      "experiment_viquae_fast.py\r\n",
      "experiment_viquae.ipynb\r\n",
      "experiment_viquae.py\r\n",
      "experiment_viquae_transfer_learning-Copy1.ipynb\r\n",
      "experiment_viquae_transfer_learning.ipynb\r\n",
      "experiment_viquae_transfer_learning_train-Copy1.ipynb\r\n",
      "experiment_viquae_transfer_learning_train.ipynb\r\n",
      "foo.py\r\n",
      "history.py\r\n",
      "\u001b[38;5;27mlogs\u001b[0m/\r\n",
      "\u001b[38;5;27mmodels\u001b[0m/\r\n",
      "prepare_topk_revisited.ipynb\r\n",
      "prepare_topk_viquae.ipynb\r\n",
      "prepare_topk_viquae_test.ipynb\r\n",
      "prepare_topk_viquae_train.ipynb\r\n",
      "ranx_compare_ablation_study.ipynb\r\n",
      "README.md\r\n",
      "\u001b[38;5;27mrrt_gld_ckpts\u001b[0m/\r\n",
      "\u001b[38;5;27mrrt_scripts\u001b[0m/\r\n",
      "swagg.py\r\n",
      "swing.py\r\n",
      "to_bin_experiment_new_viquae.ipynb\r\n",
      "to_bin_experiment_viquae.ipynb\r\n",
      "to_bin_gnd_exploration.ipynb\r\n",
      "\u001b[38;5;27mtools\u001b[0m/\r\n",
      "tutoqrels_dict\r\n",
      "tutorun_dict_500\r\n",
      "Untitled.ipynb\r\n",
      "untitled.txt\r\n",
      "\u001b[38;5;27mutils\u001b[0m/\r\n",
      "viquae_for_rrt_training_data_preparation.ipynb\r\n",
      "zut_qrels\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': 0.30367103352657826,\n",
       " 'mrr': 0.4656070796279204,\n",
       " 'precision': 0.13010005331583033,\n",
       " 'hit_rate': 0.84,\n",
       " 'recall': 0.8353333333333333,\n",
       " 'map@1': 0.12387409396936318,\n",
       " 'mrr@1': 0.3848,\n",
       " 'precision@1': 0.3848,\n",
       " 'hit_rate@1': 0.3848,\n",
       " 'recall@1': 0.12387409396936318,\n",
       " 'map@5': 0.17727036704097332,\n",
       " 'mrr@5': 0.4441866666666667,\n",
       " 'precision@5': 0.19888,\n",
       " 'hit_rate@5': 0.536,\n",
       " 'recall@5': 0.21326514242793831,\n",
       " 'map@10': 0.20285686253505622,\n",
       " 'mrr@10': 0.45554571428571433,\n",
       " 'precision@10': 0.16256,\n",
       " 'hit_rate@10': 0.6208,\n",
       " 'recall@10': 0.2925221308673156}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, runs[1], m_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares different runs and performs statistical tests (Fisher's Randomization test)\n",
    "report = compare(\n",
    "    qrels,\n",
    "    runs,\n",
    "    metrics=metrics,\n",
    "    max_p=0.01,  # P-value threshold\n",
    "    # Use `fisher` for Fisher's Randomization Test (slower) \n",
    "    # or `student` for Two-sided Paired Student's t-Test (faster)\n",
    "    rounding_digits=3,\n",
    "    show_percentages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#    Model      MAP    MRR    P@1    Recall@1    P@5    Hit_Rate@5    Recall@5    P@10    Hit_Rate@10    Recall@10\n",
       "---  -------  -----  -----  -----  ----------  -----  ------------  ----------  ------  -------------  -----------\n",
       "a    run_1     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "b    run_2     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "c    run_3     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "d    run_4     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "e    run_5     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "f    run_6     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "g    run_7     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "h    run_8     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3\n",
       "i    run_9     30.4   46.6   38.5        12.4   19.9          53.6        21.3    16.3           62.1         29.3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = 'dev'\n",
    "set_name = 'tuto'\n",
    "eval_set_name = set_name\n",
    "train_txt = set_name+'_query.txt'\n",
    "test_txt = (set_name+'_query.txt', set_name+'_selection.txt')\n",
    "train_data_dir = 'data/viquae_for_rrt'\n",
    "test_data_dir  = 'data/viquae_for_rrt'\n",
    "test_gnd_file = 'gnd_'+ set_name+'.pkl'\n",
    "train_gnd_file = 'gnd_'+ set_name+'.pkl'\n",
    "desc_name = 'r50_gldv2'\n",
    "split_char  = ';;'\n",
    "sampler = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = False\n",
    "cudnn_flag = 'benchmark'\n",
    "temp_dir = osp.join('logs', 'temp')\n",
    "resume = '/mnt/beegfs/home/smessoud/RerankingTransformer/RRT_GLD/rrt_gld_ckpts/r50_gldv1.pt'\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'viquae_for_rrt'\n",
    "data_dir = osp.join('/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size      = 16\n",
    "test_batch_size = 16\n",
    "max_sequence_len = 1000\n",
    "sampler = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'rrt'\n",
    "num_global_features = 2048  \n",
    "num_local_features = 128  \n",
    "seq_len = 1004\n",
    "dim_K = 256\n",
    "dim_feedforward = 1024\n",
    "nhead = 4\n",
    "num_encoder_layers = 6\n",
    "dropout = 0.0 \n",
    "activation = \"relu\"\n",
    "normalize_before = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8  # number of workers used ot load the data\n",
    "pin_memory  = True  # use the pin_memory option of DataLoader \n",
    "num_candidates = 100\n",
    "recalls = [1, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f95156217f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() and not cpu else 'cpu')\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cudnn_flag == 'deterministic':\n",
    "    setattr(cudnn, cudnn_flag, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(desc_name, \n",
    "        train_data_dir, test_data_dir, train_txt, \n",
    "        test_txt, train_gnd_file,  test_gnd_file,\n",
    "        max_sequence_len, split_char):\n",
    "    ####################################################################################################################################\n",
    "    if len(train_txt) == 2:\n",
    "        train_gnd_data  = None if train_gnd_file is None else pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "        train_lines     = read_file(osp.join(train_data_dir, train_txt[1]))\n",
    "        train_q_lines   = read_file(osp.join(train_data_dir, train_txt[0]))\n",
    "        train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "        train_q_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_q_lines]\n",
    "        train_set       = FeatureDataset(train_data_dir, train_samples,   desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "        query_train_set = FeatureDataset(train_data_dir, train_q_samples, desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "    else:\n",
    "        train_gnd_data  = None if train_gnd_file is None else pickle_load(osp.join(train_data_dir, train_gnd_file))\n",
    "        train_lines     = read_file(osp.join(train_data_dir, train_txt))\n",
    "        train_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in train_lines]\n",
    "        train_set       = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "        query_train_set = FeatureDataset(train_data_dir, train_samples, desc_name, max_sequence_len, gnd_data=train_gnd_data)\n",
    "        ####################################################################################################################################\n",
    "    test_gnd_data   = None if test_gnd_file is None else pickle_load(osp.join(test_data_dir, test_gnd_file))\n",
    "    query_lines     = read_file(osp.join(test_data_dir, test_txt[0]))\n",
    "    gallery_lines   = read_file(osp.join(test_data_dir, test_txt[1]))\n",
    "    query_samples   = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in query_lines]\n",
    "    gallery_samples = [(line.split(split_char)[0], int(line.split(split_char)[1]), int(line.split(split_char)[2]), int(line.split(split_char)[3])) for line in gallery_lines]\n",
    "    gallery_set     = FeatureDataset(test_data_dir, gallery_samples, desc_name, max_sequence_len)\n",
    "    query_set       = FeatureDataset(test_data_dir, query_samples,   desc_name, max_sequence_len, gnd_data=test_gnd_data)\n",
    "        \n",
    "    return (train_set, query_train_set), (query_set, gallery_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLoaders(NamedTuple):\n",
    "    train: DataLoader\n",
    "    num_classes: int\n",
    "    query: DataLoader\n",
    "    query_train: DataLoader\n",
    "    set_name: str = ''\n",
    "    eval_set_name: str = ''\n",
    "    gallery: Optional[DataLoader] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(desc_name, train_data_dir, \n",
    "    batch_size, test_batch_size, \n",
    "    num_workers, pin_memory, \n",
    "    sampler, recalls, set_name, \n",
    "    eval_set_name, train_gnd_file,\n",
    "    num_candidates=100,):\n",
    "\n",
    "    (train_set, query_train_set), (query_set, gallery_set) = get_sets(desc_name, \n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=train_data_dir,\n",
    "        train_txt=set_name+'_query.txt',\n",
    "        test_txt=(set_name+'_query.txt', set_name+'_selection.txt'),\n",
    "        test_gnd_file=test_gnd_file, \n",
    "        train_gnd_file=train_gnd_file,\n",
    "        split_char=split_char,\n",
    "        max_sequence_len=500)\n",
    "\n",
    "    if sampler == 'random':\n",
    "        train_sampler = BatchSampler(RandomSampler(train_set), batch_size=batch_size, drop_last=False)\n",
    "    elif sampler == 'triplet':\n",
    "        train_nn_inds = osp.join(train_data_dir, set_name + '_nn_inds_%s.pkl'%desc_name)\n",
    "        gnd_data = train_set.gnd_data['gnd']\n",
    "        train_sampler = TripletSampler(query_train_set.targets, batch_size, train_nn_inds, num_candidates, gnd_data)\n",
    "    else:\n",
    "        raise ValueError('Invalid choice of sampler ({}).'.format(sampler))\n",
    "    train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    query_train_loader = DataLoader(query_train_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "    query_loader   = DataLoader(query_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    gallery_loader = DataLoader(gallery_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return MetricLoaders(train=train_loader, query_train=query_train_loader, query=query_loader, gallery=gallery_loader, num_classes=len(train_set.categories),set_name=set_name,eval_set_name=eval_set_name), recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision_viquae_rerank(\n",
    "    model: nn.Module,\n",
    "    cache_nn_inds: torch.Tensor,\n",
    "    query_global: torch.Tensor, query_local: torch.Tensor, query_mask: torch.Tensor, query_scales: torch.Tensor, query_positions: torch.Tensor,\n",
    "    gallery_global: torch.Tensor, gallery_local: torch.Tensor, gallery_mask: torch.Tensor, gallery_scales: torch.Tensor, gallery_positions: torch.Tensor,\n",
    "    ks: List[int],\n",
    "    gnd) -> Dict[str, float]:\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    query_global    = query_global.to(device)\n",
    "    query_local     = query_local.to(device)\n",
    "    query_mask      = query_mask.to(device)\n",
    "    query_scales    = query_scales.to(device)\n",
    "    query_positions = query_positions.to(device)\n",
    "\n",
    "    num_samples, top_k = cache_nn_inds.size()\n",
    "    top_k = min(100, top_k)\n",
    "    \n",
    "    sizes = [len(gnd['simlist'][i]) for i in range(len(gnd['simlist']))]\n",
    "    \n",
    "    gallery_global    = fill_in_and_pad(gallery_global, query_global, sizes)\n",
    "    gallery_local     = fill_in_and_pad(gallery_local, query_local, sizes)\n",
    "    gallery_mask      = fill_in_and_pad(gallery_mask, query_mask, sizes)\n",
    "    gallery_scales    = fill_in_and_pad(gallery_scales, query_scales, sizes)\n",
    "    gallery_positions = fill_in_and_pad(gallery_positions, query_positions, sizes)\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    ## Evaluation\n",
    "    eval_nn_inds = deepcopy(cache_nn_inds.cpu().data.numpy())\n",
    "\n",
    "    ## Exclude the junk images as in DELG (https://github.com/tensorflow/models/blob/44cad43aadff9dd12b00d4526830f7ea0796c047/research/delf/delf/python/detect_to_retrieve/image_reranking.py#L190)\n",
    "    #for i in range(num_samples):\n",
    "    #    junk_ids = gnd['gnd'][i]['r_neg']\n",
    "    #    all_ids = eval_nn_inds[i]\n",
    "    #    pos = np.in1d(all_ids, junk_ids)\n",
    "    #    neg = np.array([not x for x in pos])\n",
    "    #    new_ids = np.concatenate([np.arange(len(all_ids))[neg], np.arange(len(all_ids))[pos]])\n",
    "    #    new_ids = all_ids[new_ids]\n",
    "    #    eval_nn_inds[i] = new_ids\n",
    "    eval_nn_inds = torch.from_numpy(eval_nn_inds)\n",
    "    \n",
    "    scores = []\n",
    "    for i in tqdm(range(top_k)):\n",
    "        nnids = eval_nn_inds[:, i]\n",
    "        topk_scores =  []\n",
    "        for iterator in range(nnids.size(dim=0)):\n",
    "            index_global = gallery_global[iterator, nnids[iterator]]\n",
    "            index_local = gallery_local[iterator, nnids[iterator]]\n",
    "            index_mask = gallery_mask[iterator, nnids[iterator]]\n",
    "            index_scales = gallery_scales[iterator, nnids[iterator]]\n",
    "            index_positions = gallery_positions[iterator, nnids[iterator]]\n",
    "            \n",
    "            index_global = index_global.unsqueeze(dim=0)\n",
    "            index_global = index_global.type(torch.float32)\n",
    "\n",
    "            index_local = index_local.unsqueeze(dim=0)\n",
    "            index_local = index_local.type(torch.float32)\n",
    "\n",
    "            index_mask = index_mask.unsqueeze(dim=0)\n",
    "            index_mask = index_mask.type(torch.bool)\n",
    "\n",
    "            index_scales = index_scales.unsqueeze(dim=0)\n",
    "            index_scales = index_scales.type(torch.int64)\n",
    "\n",
    "            index_positions = index_positions.unsqueeze(dim=0)\n",
    "            index_positions = index_positions.type(torch.float32)\n",
    "            \n",
    "            q_global = query_global[iterator].unsqueeze(dim=0)\n",
    "            q_local = query_local[iterator].unsqueeze(dim=0)\n",
    "            q_mask = query_mask[iterator].unsqueeze(dim=0)\n",
    "            q_scales = query_scales[iterator].unsqueeze(dim=0)\n",
    "            q_positions = query_positions[iterator].unsqueeze(dim=0)\n",
    "\n",
    "            iter_scores = model(\n",
    "            q_global, q_local, q_mask, q_scales, q_positions,\n",
    "                index_global.to(device),\n",
    "                index_local.to(device),\n",
    "                index_mask.to(device),\n",
    "                index_scales.to(device),\n",
    "                index_positions.to(device))\n",
    "            \n",
    "            topk_scores.append(iter_scores.cpu().data)\n",
    "        \n",
    "        current_scores = torch.from_numpy(np.stack(topk_scores, axis=0)).squeeze(1)\n",
    "        torch.cuda.empty_cache()        \n",
    "        scores.append(current_scores.cpu().data)\n",
    "    \n",
    "    \n",
    "    scores = torch.stack(scores, -1) # nb_queries x 100\n",
    "    closest_dists, indices = torch.sort(scores, dim=-1, descending=True)\n",
    "    closest_indices = torch.gather(eval_nn_inds, -1, indices)\n",
    "    ranks = deepcopy(eval_nn_inds)\n",
    "    ranks[:, :top_k] = deepcopy(closest_indices)\n",
    "    ranks = ranks.cpu().data.numpy()\n",
    "    ranks = remove_padded_indices(ranks, eval_nn_inds, sizes)\n",
    "    \n",
    "    out = compute_metrics('viquae', ranks.T, gnd['gnd'], sizes, kappas=ks)\n",
    "\n",
    "    ########################################################################################  \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_global_features, num_local_features, seq_len, dim_K, dim_feedforward, nhead, num_encoder_layers, dropout, activation, normalize_before):\n",
    "    return MatchERT(d_global=num_global_features, d_model=num_local_features, seq_len=seq_len, d_K=dim_K, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, activation=activation, normalize_before=normalize_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_viquae(\n",
    "        model: nn.Module,\n",
    "        cache_nn_inds: torch.Tensor,\n",
    "        query_loader: DataLoader,\n",
    "        gallery_loader: DataLoader,\n",
    "        recall: List[int]):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    to_device = lambda x: x.to(device, non_blocking=True)\n",
    "\n",
    "    query_global, query_local, query_mask, query_scales, query_positions, query_names = [], [], [], [], [], []\n",
    "    gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names = [], [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for entry in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "            q_global, q_local, q_mask, q_scales, q_positions, _, q_names = entry\n",
    "            query_global.append(q_global.cpu())\n",
    "            query_local.append(q_local.cpu())\n",
    "            query_mask.append(q_mask.cpu())\n",
    "            query_scales.append(q_scales.cpu())\n",
    "            query_positions.append(q_positions.cpu())\n",
    "            query_names.extend(list(q_names))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        query_global    = torch.cat(query_global, 0)\n",
    "        query_local     = torch.cat(query_local, 0)\n",
    "        query_mask      = torch.cat(query_mask, 0)\n",
    "        query_scales    = torch.cat(query_scales, 0)\n",
    "        query_positions = torch.cat(query_positions, 0)\n",
    "\n",
    "        for entry in tqdm(gallery_loader, desc='Extracting gallery features', leave=False, ncols=80):\n",
    "            g_global, g_local, g_mask, g_scales, g_positions, _, g_names = entry\n",
    "            gallery_global.append(g_global.cpu())\n",
    "            gallery_local.append(g_local.cpu())\n",
    "            gallery_mask.append(g_mask.cpu())\n",
    "            gallery_scales.append(g_scales.cpu())\n",
    "            gallery_positions.append(g_positions.cpu())\n",
    "            gallery_names.extend(list(g_names))\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        gallery_global    = torch.cat(gallery_global, 0)\n",
    "        gallery_local     = torch.cat(gallery_local, 0)\n",
    "        gallery_mask      = torch.cat(gallery_mask, 0)\n",
    "        gallery_scales    = torch.cat(gallery_scales, 0)\n",
    "        gallery_positions = torch.cat(gallery_positions, 0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        evaluate_function = partial(mean_average_precision_viquae_rerank, model=model, cache_nn_inds=cache_nn_inds,\n",
    "            query_global=query_global, query_local=query_local, query_mask=query_mask, query_scales=query_scales, query_positions=query_positions, \n",
    "            gallery_global=gallery_global, gallery_local=gallery_local, gallery_mask=gallery_mask, gallery_scales=gallery_scales, gallery_positions=gallery_positions, \n",
    "            ks=recall, \n",
    "            gnd=query_loader.dataset.gnd_data,\n",
    "        )\n",
    "        metrics = evaluate_function()\n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_and_pad(gallery_in, query, sizes):\n",
    "    shape = list(query.shape)\n",
    "    shape.insert(1, 100)\n",
    "    gallery_out = torch.zeros(shape)\n",
    "    size = 0\n",
    "    counter = 0\n",
    "    for i in range(gallery_out.size(dim=0)):\n",
    "        for j in range(gallery_out.size(dim=1)):\n",
    "            if j < sizes[i]:\n",
    "                gallery_out[i][j] = gallery_in[counter]\n",
    "                counter += 1\n",
    "    \n",
    "    return gallery_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padded_indices(rankings, nn_inds, sizes):\n",
    "    # rankings.shape -> (nb_queries x 100)\n",
    "    assert(len(rankings) == len(sizes))\n",
    "    for i in range(len(sizes)):\n",
    "        assert(max(nn_inds[i, :sizes[i]]) < sizes[i])\n",
    "        rankings[i, :sizes[i]] = np.array([value for value in rankings[i] if value < sizes[i]])\n",
    "        rankings[i, sizes[i]:] = nn_inds[i, sizes[i]:]\n",
    "        \n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampler == 'random':\n",
    "   train_sampler = BatchSampler(RandomSampler(train_set), batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "query_train_loader = DataLoader(query_train_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loader   = DataLoader(query_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "gallery_loader = DataLoader(gallery_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders, recall_ks = get_loaders(desc_name=desc_name,\n",
    "    train_data_dir=train_data_dir, \n",
    "    batch_size=36, test_batch_size=36, \n",
    "    num_workers=8, pin_memory=True, \n",
    "    sampler='random', recalls=[1, 5, 10], \n",
    "    set_name=set_name, eval_set_name=None,\n",
    "    train_gnd_file=None, num_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ingredient = Ingredient('model', interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_global_features,num_local_features,seq_len,dim_K,dim_feedforward,nhead,num_encoder_layers,dropout,activation,normalize_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume is not None:\n",
    "   checkpoint = torch.load(resume, map_location=torch.device('cpu'))\n",
    "   model.load_state_dict(checkpoint['state'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchERT(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (remap): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (scale_encoder): Embedding(7, 128)\n",
       "  (seg_encoder): Embedding(6, 128)\n",
       "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuto'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.set_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('r50_gldv2',\n",
       " 'r50_gldv2',\n",
       " '/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.query.dataset.desc_name, loaders.query.dataset.desc_name, loaders.query.dataset.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f94a97ea550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_inds_path = osp.join(loaders.query.dataset.data_dir, set_name+'_nn_inds_%s.pkl'%loaders.query.dataset.desc_name)\n",
    "cache_nn_inds = torch.from_numpy(pickle_load(nn_inds_path)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/beegfs/home/smessoud/RerankingTransformer/models/research/delf/delf/python/delg/data/viquae_for_rrt/tuto_nn_inds_r50_gldv2.pkl'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_inds_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_nn_inds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, top_k = cache_nn_inds.size()\n",
    "top_k = min(top_k, 100)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "to_device = lambda x: x.to(device, non_blocking=True)\n",
    "\n",
    "query_global, query_local, query_mask, query_scales, query_positions, query_names = [], [], [], [], [], []\n",
    "gallery_global, gallery_local, gallery_mask, gallery_scales, gallery_positions, gallery_names = [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for entry in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "    q_global, q_local, q_mask, q_scales, q_positions, _, q_names = entry\n",
    "    query_global.append(q_global.cpu())\n",
    "    query_local.append(q_local.cpu())\n",
    "    query_mask.append(q_mask.cpu())\n",
    "    query_scales.append(q_scales.cpu())\n",
    "    query_positions.append(q_positions.cpu())\n",
    "    query_names.extend(list(q_names))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_global    = torch.cat(query_global, 0)\n",
    "query_local     = torch.cat(query_local, 0)\n",
    "query_mask      = torch.cat(query_mask, 0)\n",
    "query_scales    = torch.cat(query_scales, 0)\n",
    "query_positions = torch.cat(query_positions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for entry in tqdm(gallery_loader, desc='Extracting gallery features', leave=False, ncols=80):\n",
    "    g_global, g_local, g_mask, g_scales, g_positions, _, g_names = entry\n",
    "    gallery_global.append(g_global.cpu())\n",
    "    gallery_local.append(g_local.cpu())\n",
    "    gallery_mask.append(g_mask.cpu())\n",
    "    gallery_scales.append(g_scales.cpu())\n",
    "    gallery_positions.append(g_positions.cpu())\n",
    "    gallery_names.extend(list(g_names))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_global    = torch.cat(gallery_global, 0)\n",
    "gallery_local     = torch.cat(gallery_local, 0)\n",
    "gallery_mask      = torch.cat(gallery_mask, 0)\n",
    "gallery_scales    = torch.cat(gallery_scales, 0)\n",
    "gallery_positions = torch.cat(gallery_positions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5858, 2048]),\n",
       " torch.Size([5858, 500, 128]),\n",
       " torch.Size([5858, 500]),\n",
       " torch.Size([5858, 500]),\n",
       " torch.Size([5858, 500, 2]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_global.shape, gallery_local.shape, gallery_mask.shape, gallery_scales.shape, gallery_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(model.parameters()).device\n",
    "query_global    = query_global.to(device)\n",
    "query_local     = query_local.to(device)\n",
    "query_mask      = query_mask.to(device)\n",
    "query_scales    = query_scales.to(device)\n",
    "query_positions = query_positions.to(device)\n",
    "\n",
    "num_samples, top_k = cache_nn_inds.size()\n",
    "top_k = min(100, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_data = pickle_load(osp.join(data_dir, test_gnd_file))\n",
    "gnd = pickle_load(osp.join(data_dir, test_gnd_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(gnd['simlist'][i]) for i in range(len(gnd['simlist']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gallery_global    = fill_in_and_pad(gallery_global, query_global, sizes)\n",
    "gallery_local     = fill_in_and_pad(gallery_local, query_local, sizes)\n",
    "gallery_mask      = fill_in_and_pad(gallery_mask, query_mask, sizes)\n",
    "gallery_scales    = fill_in_and_pad(gallery_scales, query_scales, sizes)\n",
    "gallery_positions = fill_in_and_pad(gallery_positions, query_positions, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_nn_inds = deepcopy(cache_nn_inds.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Exclude the junk images as in DELG (https://github.com/tensorflow/models/blob/44cad43aadff9dd12b00d4526830f7ea0796c047/research/delf/delf/python/detect_to_retrieve/image_reranking.py#L190)\n",
    "#for i in range(num_samples):\n",
    "#    junk_ids = gnd['gnd'][i]['r_neg']\n",
    "#    all_ids = eval_nn_inds[i]\n",
    "#    pos = np.in1d(all_ids, junk_ids)\n",
    "#    neg = np.array([not x for x in pos])\n",
    "#    new_ids = np.concatenate([np.arange(len(all_ids))[neg], np.arange(len(all_ids))[pos]])\n",
    "#    new_ids = all_ids[new_ids]\n",
    "#    eval_nn_inds[i] = new_ids\n",
    "eval_nn_inds = torch.from_numpy(eval_nn_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:24<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(top_k)):\n",
    "    nnids = eval_nn_inds[:, i]\n",
    "    topk_scores =  []\n",
    "    for iterator in range(nnids.size(dim=0)):\n",
    "        index_global = gallery_global[iterator, nnids[iterator]]\n",
    "        index_local = gallery_local[iterator, nnids[iterator]]\n",
    "        index_mask = gallery_mask[iterator, nnids[iterator]]\n",
    "        index_scales = gallery_scales[iterator, nnids[iterator]]\n",
    "        index_positions = gallery_positions[iterator, nnids[iterator]]\n",
    "\n",
    "        index_global = index_global.unsqueeze(dim=0)\n",
    "        index_global = index_global.type(torch.float32)\n",
    "\n",
    "        index_local = index_local.unsqueeze(dim=0)\n",
    "        index_local = index_local.type(torch.float32)\n",
    "\n",
    "        index_mask = index_mask.unsqueeze(dim=0)\n",
    "        index_mask = index_mask.type(torch.bool)\n",
    "\n",
    "        index_scales = index_scales.unsqueeze(dim=0)\n",
    "        index_scales = index_scales.type(torch.int64)\n",
    "\n",
    "        index_positions = index_positions.unsqueeze(dim=0)\n",
    "        index_positions = index_positions.type(torch.float32)\n",
    "\n",
    "        q_global = query_global[iterator].unsqueeze(dim=0)\n",
    "        q_local = query_local[iterator].unsqueeze(dim=0)\n",
    "        q_mask = query_mask[iterator].unsqueeze(dim=0)\n",
    "        q_scales = query_scales[iterator].unsqueeze(dim=0)\n",
    "        q_positions = query_positions[iterator].unsqueeze(dim=0)\n",
    "\n",
    "        iter_scores = model(\n",
    "        q_global, q_local, q_mask, q_scales, q_positions,\n",
    "            index_global.to(device),\n",
    "            index_local.to(device),\n",
    "            index_mask.to(device),\n",
    "            index_scales.to(device),\n",
    "            index_positions.to(device))\n",
    "\n",
    "        topk_scores.append(iter_scores.cpu().data)\n",
    "\n",
    "    current_scores = torch.from_numpy(np.stack(topk_scores, axis=0)).squeeze(1)\n",
    "    torch.cuda.empty_cache()        \n",
    "    scores.append(current_scores.cpu().data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "def compute_metrics(dataset, ranks, gnd, sizes=[], kappas=[1, 5, 10], set_name=None, max_sequence_len=None):\n",
    "    # old evaluation protocol\n",
    "    if dataset.startswith('classic'):\n",
    "        map, aps, _, _ = compute_map(ranks, gnd)\n",
    "        out = {'map': np.around(map*100, decimals=3)}\n",
    "        print('>> {}: mAP {:.2f}'.format(dataset, out['map']))\n",
    "     \n",
    "    # new evaluation protocol for revisited dataset\n",
    "    elif dataset.startswith('revisited'):\n",
    "        \n",
    "        gnd_t = []\n",
    "        for i in range(len(gnd)):\n",
    "            g = {}\n",
    "            g['ok'] = np.concatenate([gnd[i]['easy']])\n",
    "            g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['hard']])\n",
    "            gnd_t.append(g)\n",
    "        mapE, apsE, mprE, prsE = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "        gnd_t = []\n",
    "        for i in range(len(gnd)):\n",
    "            g = {}\n",
    "            g['ok'] = np.concatenate([gnd[i]['easy'], gnd[i]['hard']])\n",
    "            g['junk'] = np.concatenate([gnd[i]['junk']])\n",
    "            gnd_t.append(g)\n",
    "        mapM, apsM, mprM, prsM = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "        gnd_t = []\n",
    "        for i in range(len(gnd)):\n",
    "            g = {}\n",
    "            g['ok'] = np.concatenate([gnd[i]['hard']])\n",
    "            g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['easy']])\n",
    "            gnd_t.append(g)\n",
    "        mapH, apsH, mprH, prsH = compute_map(ranks, gnd_t, kappas)\n",
    "\n",
    "\n",
    "        out = {\n",
    "            'E_map': np.around(mapE*100, decimals=2),\n",
    "            'M_map': np.around(mapM*100, decimals=2),\n",
    "            'H_map': np.around(mapH*100, decimals=2),\n",
    "            'E_mp':  np.around(mprE*100, decimals=2),\n",
    "            'M_mp':  np.around(mprM*100, decimals=2),\n",
    "            'H_mp':  np.around(mprH*100, decimals=2),\n",
    "            # 'apsE': apsE.tolist(),\n",
    "            # 'apsM': apsM.tolist(),\n",
    "            # 'apsH': apsH.tolist(),\n",
    "        }\n",
    "\n",
    "        # with open('medium.txt', 'w') as f:\n",
    "        #     f.write('\\n'.join([str(v) for v in apsM]))\n",
    "        # with open('hard.txt', 'w') as f:\n",
    "        #     f.write('\\n'.join([str(v) for v in apsH]))\n",
    "        # with open('easy.txt', 'w') as f:\n",
    "        #     f.write('\\n'.join([str(v) for v in apsE]))\n",
    "\n",
    "        print('>> {}: mAP E: {}, M: {}, H: {}'.format(dataset, out['E_map'], out['M_map'], out['H_map']))\n",
    "        print('>> {}: mP@k{} E: {}, M: {}, H: {}'.format(dataset, kappas, out['E_mp'], out['M_mp'], out['H_mp']))\n",
    "    \n",
    "    # new evaluation protocol for viquae dataset\n",
    "    elif dataset.startswith('viquae'):\n",
    "        metrics = [\"map\", \"mrr\", \"precision\", \"hit_rate\", \"recall\"]\n",
    "        m_list = [metric for metric in metrics]\n",
    "        \n",
    "        for i in range(len(kappas)):\n",
    "            m_list.extend([metric+'@'+str(kappas[i]) for metric in metrics])\n",
    "        \n",
    "        qrels_dict = {}\n",
    "        run_dict = {}\n",
    "        \n",
    "        for i in range(ranks.T.shape[0]):\n",
    "            size = sizes[i]\n",
    "            q_str = \"q_\"+str(int(i))\n",
    "            ok_inds = np.concatenate([gnd[i]['r_easy'], gnd[i]['r_hard']])\n",
    "            \n",
    "            if len(ok_inds) == 0:\n",
    "                qrels_dict[q_str] = {\"DUMMY_RUN\": 0}\n",
    "            else:\n",
    "                qrels_dict[q_str] = dict([('d_' + str(int(key)), 1) for key in ok_inds])\n",
    "            \n",
    "            run_dict[q_str]   = dict([('d_' + str(int(key)), 1) for key in ranks[:size,i]])\n",
    "            \n",
    "        qrels = Qrels(qrels_dict)\n",
    "        run = Run(run_dict)\n",
    "        \n",
    "        if set_name:\n",
    "            json_save(set_name+'_qrels_dict', qrels_dict)\n",
    "            json_save(set_name+'_run_dict_'+str(max_sequence_len), run_dict)\n",
    "        \n",
    "        out = evaluate(qrels, run, m_list)\n",
    "        \n",
    "        for key, value in out.items():\n",
    "            out[key] = np.around(value*100, decimals=2)\n",
    "    print(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.6, 'mrr': 33.46, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 7.39, 'mrr@1': 20.83, 'precision@1': 20.83, 'hit_rate@1': 20.83, 'recall@1': 7.39, 'map@5': 13.61, 'mrr@5': 30.81, 'precision@5': 15.67, 'hit_rate@5': 47.5, 'recall@5': 20.78, 'map@10': 16.81, 'mrr@10': 32.14, 'precision@10': 14.08, 'hit_rate@10': 57.5, 'recall@10': 29.67}\n"
     ]
    }
   ],
   "source": [
    "scores = torch.stack(scores, -1) # nb_queries x 100\n",
    "closest_dists, indices = torch.sort(scores, dim=-1, descending=True)\n",
    "closest_indices = torch.gather(eval_nn_inds, -1, indices)\n",
    "ranks = deepcopy(eval_nn_inds)\n",
    "ranks[:, :top_k] = deepcopy(closest_indices)\n",
    "ranks = ranks.cpu().data.numpy()\n",
    "ranks = remove_padded_indices(ranks, eval_nn_inds, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 26.6, 'mrr': 33.46, 'precision': 13.83, 'hit_rate': 85.0, 'recall': 84.58, 'map@1': 7.39, 'mrr@1': 20.83, 'precision@1': 20.83, 'hit_rate@1': 20.83, 'recall@1': 7.39, 'map@5': 13.61, 'mrr@5': 30.81, 'precision@5': 15.67, 'hit_rate@5': 47.5, 'recall@5': 20.78, 'map@10': 16.81, 'mrr@10': 32.14, 'precision@10': 14.08, 'hit_rate@10': 57.5, 'recall@10': 29.67}\n"
     ]
    }
   ],
   "source": [
    "out = compute_metrics('viquae', ranks.T, gnd['gnd'], sizes, kappas=ks, set_name=loaders.set_name, max_sequence_len=loaders.query.dataset.max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.query.dataset.max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
